{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Game.LeducGame import *\n",
    "from Environment.Environment import *\n",
    "from Opponent_agent.RandAgent import *\n",
    "from Opponent_agent.GreedyAgent import *\n",
    "from Opponent_agent.HumanAgent import *\n",
    "from Qagent.QAgent import *\n",
    "\n",
    "stack_size=5\n",
    "random_agent_qtable=None\n",
    "greedy_agent_qtable=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_number=100000\n",
    "evaluate_every=5000\n",
    "test_number=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qAgent vs RandAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.     1.     0.288]\n",
      "  [-1.     1.     0.44 ]\n",
      "  [-1.     1.     0.631]\n",
      "  [-1.     1.     0.382]\n",
      "  [-1.     1.     0.492]\n",
      "  [-1.     1.     0.56 ]\n",
      "  [-1.     0.    -0.299]\n",
      "  [-1.     0.    -0.702]\n",
      "  [-1.     0.     0.352]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-1.     0.234  0.064]\n",
      "  [-1.    -0.095  0.419]\n",
      "  [-1.     0.147  0.486]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-1.     0.858  0.484]\n",
      "  [-1.     0.798  0.902]\n",
      "  [-1.     0.675  0.394]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-0.998  0.994  0.996]\n",
      "  [-1.    -0.773  0.387]\n",
      "  [-0.998 -0.783  0.999]\n",
      "  [-1.    -0.384  0.35 ]\n",
      "  [-0.985  0.995  0.984]\n",
      "  [-0.998  0.764  0.998]\n",
      "  [-1.     0.676  0.747]\n",
      "  [-0.998  0.499  0.428]\n",
      "  [-0.953  0.987  0.966]\n",
      "  [-0.958  0.     0.935]\n",
      "  [-1.     0.    -1.   ]\n",
      "  [-1.     0.    -1.   ]\n",
      "  [-1.     0.    -0.912]\n",
      "  [-0.746  0.     0.651]\n",
      "  [-1.     0.    -0.875]\n",
      "  [-1.     0.    -0.607]\n",
      "  [-1.     0.    -0.932]\n",
      "  [-0.718  0.     0.878]]\n",
      "\n",
      " [[-1.     1.967 -0.708]\n",
      "  [-1.     1.925  0.875]\n",
      "  [-1.     1.959  0.668]\n",
      "  [-1.     1.812  0.462]\n",
      "  [-1.     1.891  0.441]\n",
      "  [-1.     1.822  0.832]\n",
      "  [-1.     0.    -1.081]\n",
      "  [-1.     0.    -0.709]\n",
      "  [-1.     0.     0.964]\n",
      "  [-1.     1.174  1.279]\n",
      "  [-1.     0.505  0.196]\n",
      "  [-1.     0.12  -0.304]\n",
      "  [-1.     0.352 -0.632]\n",
      "  [-1.     1.064  1.037]\n",
      "  [-1.     1.04   0.566]\n",
      "  [-1.     0.98  -0.057]\n",
      "  [-1.     0.8    0.215]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-1.     1.     1.129]\n",
      "  [-1.    -0.842  0.472]\n",
      "  [-1.    -0.909  1.   ]\n",
      "  [-1.    -0.597  0.283]\n",
      "  [-1.     1.     1.042]\n",
      "  [-1.     0.514  1.   ]\n",
      "  [-1.     0.672  0.913]\n",
      "  [-1.     0.33   0.762]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-0.999  0.     1.994]\n",
      "  [-1.     0.    -2.   ]\n",
      "  [-1.     0.    -2.   ]\n",
      "  [-1.     0.    -1.881]\n",
      "  [-0.891  0.     1.757]\n",
      "  [-1.     0.    -1.41 ]\n",
      "  [-1.     0.    -1.262]\n",
      "  [-1.     0.    -1.734]\n",
      "  [-0.953  0.     1.915]]\n",
      "\n",
      " [[-1.     2.786 -0.241]\n",
      "  [-1.     2.759 -0.413]\n",
      "  [-1.     2.882  0.17 ]\n",
      "  [-1.     2.764  0.541]\n",
      "  [-1.     2.682  0.257]\n",
      "  [-1.     2.688  0.739]\n",
      "  [-1.     0.    -2.035]\n",
      "  [-1.     0.    -0.385]\n",
      "  [-1.     0.     1.85 ]\n",
      "  [-1.     1.436  1.135]\n",
      "  [-1.     0.785  0.026]\n",
      "  [-1.     0.224  0.546]\n",
      "  [-1.     1.084 -0.986]\n",
      "  [-1.     1.185  1.259]\n",
      "  [-1.     1.172 -0.099]\n",
      "  [-1.     1.567 -0.214]\n",
      "  [-1.     1.328 -0.442]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-1.     1.     1.131]\n",
      "  [-1.    -0.831  0.348]\n",
      "  [-1.    -0.713  1.   ]\n",
      "  [-1.    -0.837  0.881]\n",
      "  [-1.     1.     1.236]\n",
      "  [-1.     0.677  1.   ]\n",
      "  [-1.     0.798  0.929]\n",
      "  [-1.     0.392  0.392]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-1.     0.     2.999]\n",
      "  [-1.     0.    -3.   ]\n",
      "  [-1.     0.    -3.   ]\n",
      "  [-1.     0.    -2.941]\n",
      "  [-0.958  0.     2.785]\n",
      "  [-1.     0.    -1.789]\n",
      "  [-1.     0.    -1.654]\n",
      "  [-1.     0.    -2.627]\n",
      "  [-0.997  0.     2.968]]\n",
      "\n",
      " [[-1.     3.695  0.677]\n",
      "  [-1.     3.804 -0.98 ]\n",
      "  [-1.     3.488  0.827]\n",
      "  [-1.     3.22   0.637]\n",
      "  [-1.     3.151 -0.446]\n",
      "  [-1.     3.689  1.053]\n",
      "  [-1.     0.    -1.843]\n",
      "  [-1.     0.     0.314]\n",
      "  [-1.     0.     1.525]\n",
      "  [-1.     1.667  1.148]\n",
      "  [-1.     1.152 -1.222]\n",
      "  [-1.     0.806 -0.765]\n",
      "  [-1.     1.357 -0.073]\n",
      "  [-1.     1.591  1.356]\n",
      "  [-1.     1.233  0.131]\n",
      "  [-1.     2.131  0.382]\n",
      "  [-1.     1.893 -0.47 ]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-1.     1.     1.816]\n",
      "  [-1.    -0.78   0.262]\n",
      "  [-1.    -0.656  1.   ]\n",
      "  [-1.    -0.5    0.494]\n",
      "  [-1.     1.     1.204]\n",
      "  [-1.     0.511  1.   ]\n",
      "  [-1.     0.634  0.947]\n",
      "  [-1.     0.594  0.284]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-1.     0.     4.   ]\n",
      "  [-1.     0.    -4.   ]\n",
      "  [-1.     0.    -4.   ]\n",
      "  [-1.     0.    -3.384]\n",
      "  [-0.991  0.     3.947]\n",
      "  [-1.     0.    -3.305]\n",
      "  [-1.     0.    -1.82 ]\n",
      "  [-1.     0.    -3.644]\n",
      "  [-0.999  0.     3.997]]\n",
      "\n",
      " [[-1.     4.956 -1.73 ]\n",
      "  [-1.     4.59   0.1  ]\n",
      "  [-1.     3.57   1.07 ]\n",
      "  [-1.     4.309 -0.395]\n",
      "  [-1.     4.558  0.811]\n",
      "  [-1.     4.665  0.868]\n",
      "  [-1.     0.    -1.774]\n",
      "  [-1.     0.    -3.325]\n",
      "  [-1.     0.     1.963]\n",
      "  [-1.     1.747  1.504]\n",
      "  [-1.     1.78  -0.71 ]\n",
      "  [-1.     0.987 -1.285]\n",
      "  [-1.     1.023  0.263]\n",
      "  [-1.     2.042  1.055]\n",
      "  [-1.     1.786  0.441]\n",
      "  [-1.     2.751  0.008]\n",
      "  [-1.     1.65  -0.649]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-1.     1.     1.328]\n",
      "  [-1.    -0.623 -0.059]\n",
      "  [-1.    -0.868  1.   ]\n",
      "  [-1.    -0.65   0.677]\n",
      "  [-1.     1.     1.797]\n",
      "  [-1.     0.794  1.   ]\n",
      "  [-1.     0.689  0.857]\n",
      "  [-1.     0.621  0.184]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-1.     0.     5.   ]\n",
      "  [-1.     0.    -5.   ]\n",
      "  [-1.     0.    -5.   ]\n",
      "  [-1.     0.    -4.548]\n",
      "  [-0.982  0.     4.977]\n",
      "  [-1.     0.    -4.151]\n",
      "  [-1.     0.    -2.059]\n",
      "  [-1.     0.    -4.545]\n",
      "  [-1.     0.     5.   ]]\n",
      "\n",
      " [[-1.     3.725  0.607]\n",
      "  [-1.     3.647 -1.071]\n",
      "  [-1.     3.816  1.378]\n",
      "  [-1.     3.467 -1.237]\n",
      "  [-1.     3.691  0.198]\n",
      "  [-1.     3.091  0.818]\n",
      "  [-1.     0.    -2.894]\n",
      "  [-1.     0.    -1.688]\n",
      "  [-1.     0.     1.219]\n",
      "  [-1.     1.642  1.46 ]\n",
      "  [-1.     1.8   -1.896]\n",
      "  [-1.    -0.024 -0.561]\n",
      "  [-1.     1.141 -0.062]\n",
      "  [-1.     1.007  1.295]\n",
      "  [-1.     1.631  0.482]\n",
      "  [-1.     1.027  0.623]\n",
      "  [-1.     2.097 -0.254]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-1.     1.     1.025]\n",
      "  [-1.    -0.834  0.167]\n",
      "  [-1.    -0.729  1.   ]\n",
      "  [-1.    -0.701  0.258]\n",
      "  [-1.     1.     1.303]\n",
      "  [-1.     0.554  1.   ]\n",
      "  [-1.     0.456  0.952]\n",
      "  [-1.     0.769  0.435]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-1.     0.     4.   ]\n",
      "  [-1.     0.    -4.   ]\n",
      "  [-1.     0.    -4.   ]\n",
      "  [-1.     0.    -3.157]\n",
      "  [-0.928  0.     3.9  ]\n",
      "  [-1.     0.    -2.922]\n",
      "  [-1.     0.    -1.64 ]\n",
      "  [-1.     0.    -3.829]\n",
      "  [-0.994  0.     3.992]]\n",
      "\n",
      " [[-1.     2.863 -0.566]\n",
      "  [-1.     2.904 -0.116]\n",
      "  [-1.     2.871  0.987]\n",
      "  [-1.     2.914 -0.15 ]\n",
      "  [-1.     2.585 -0.077]\n",
      "  [-1.     2.565  1.126]\n",
      "  [-1.     0.    -1.825]\n",
      "  [-1.     0.     0.307]\n",
      "  [-1.     0.     0.461]\n",
      "  [-1.     1.34   1.478]\n",
      "  [-1.     1.084 -0.472]\n",
      "  [-1.     0.817  0.19 ]\n",
      "  [-1.     0.271  0.138]\n",
      "  [-1.     1.163  1.245]\n",
      "  [-1.     0.89   0.298]\n",
      "  [-1.     1.408 -0.25 ]\n",
      "  [-1.     1.76   0.154]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-1.     0.998  1.548]\n",
      "  [-1.    -0.721  0.016]\n",
      "  [-1.    -0.748  1.   ]\n",
      "  [-1.    -0.674  0.678]\n",
      "  [-0.999  0.998  1.06 ]\n",
      "  [-1.     0.432  1.   ]\n",
      "  [-1.     0.85   0.886]\n",
      "  [-1.     0.311  0.828]\n",
      "  [-0.999  1.     0.999]\n",
      "  [-0.994  0.     2.974]\n",
      "  [-1.     0.    -3.   ]\n",
      "  [-1.     0.    -3.   ]\n",
      "  [-1.     0.    -2.888]\n",
      "  [-0.651  0.     2.153]\n",
      "  [-1.     0.    -2.37 ]\n",
      "  [-1.     0.    -2.133]\n",
      "  [-1.     0.    -2.262]\n",
      "  [-0.953  0.     2.785]]\n",
      "\n",
      " [[-1.     1.953 -0.181]\n",
      "  [-1.     1.747  0.072]\n",
      "  [-1.     1.887  0.89 ]\n",
      "  [-1.     1.715 -0.363]\n",
      "  [-1.     1.916  0.075]\n",
      "  [-1.     1.844  0.964]\n",
      "  [-1.     0.    -0.383]\n",
      "  [-1.     0.    -0.506]\n",
      "  [-1.     0.     0.783]\n",
      "  [-1.     1.225  1.096]\n",
      "  [-1.     0.502 -0.506]\n",
      "  [-1.     0.396  0.247]\n",
      "  [-1.     0.773  0.171]\n",
      "  [-0.999  1.018  1.25 ]\n",
      "  [-1.     0.993  0.001]\n",
      "  [-1.     1.061  0.384]\n",
      "  [-1.     1.177 -0.048]\n",
      "  [-1.     1.     1.   ]\n",
      "  [-0.988  0.997  1.014]\n",
      "  [-0.999 -0.738  0.559]\n",
      "  [-1.    -0.628  1.   ]\n",
      "  [-0.998 -0.537  0.715]\n",
      "  [-0.953  0.982  1.072]\n",
      "  [-0.993  0.659  0.995]\n",
      "  [-1.     0.663  0.987]\n",
      "  [-0.999  0.472  0.612]\n",
      "  [-0.958  0.966  0.948]\n",
      "  [-0.962  0.     1.73 ]\n",
      "  [-1.     0.    -1.997]\n",
      "  [-1.     0.    -2.   ]\n",
      "  [-1.     0.    -1.848]\n",
      "  [-0.613  0.     0.688]\n",
      "  [-1.     0.    -1.707]\n",
      "  [-1.     0.    -1.436]\n",
      "  [-1.     0.    -1.826]\n",
      "  [-0.878  0.     1.588]]\n",
      "\n",
      " [[-1.     1.     0.258]\n",
      "  [-1.     1.     0.371]\n",
      "  [-1.     1.     0.872]\n",
      "  [-1.     1.     0.318]\n",
      "  [-1.     1.     0.45 ]\n",
      "  [-1.     1.     0.785]\n",
      "  [-1.     0.    -0.435]\n",
      "  [-1.     0.    -0.088]\n",
      "  [-1.     0.     0.343]\n",
      "  [-0.969  0.966  0.966]\n",
      "  [-0.997 -0.169  0.209]\n",
      "  [-0.995 -0.157  0.514]\n",
      "  [-0.993  0.44   0.627]\n",
      "  [-0.902  0.92   0.902]\n",
      "  [-0.996  0.668  0.203]\n",
      "  [-0.994  0.891  0.556]\n",
      "  [-0.998  0.667  0.791]\n",
      "  [-0.891  0.935  0.928]\n",
      "  [-0.522  0.878  0.522]\n",
      "  [-0.953 -0.825  0.121]\n",
      "  [-0.815 -0.509  0.958]\n",
      "  [-0.953 -0.619  0.596]\n",
      "  [-0.718  0.746  0.746]\n",
      "  [-0.902  0.635  0.718]\n",
      "  [-0.865  0.812  0.856]\n",
      "  [-0.962  0.2    0.641]\n",
      "  [-0.718  0.613  0.522]\n",
      "  [-0.718  0.     0.651]\n",
      "  [-0.902  0.    -0.935]\n",
      "  [-0.962  0.    -0.911]\n",
      "  [-0.98   0.    -0.797]\n",
      "  [-0.271  0.     0.1  ]\n",
      "  [-0.942  0.    -0.844]\n",
      "  [-0.989  0.    -0.286]\n",
      "  [-0.966  0.    -0.841]\n",
      "  [-0.271  0.     0.41 ]]]\n"
     ]
    }
   ],
   "source": [
    "greedy=GreedyAgent()\n",
    "env=Environment(greedy)\n",
    "envTest=Environment(greedy)\n",
    "qagent=QAgent()\n",
    "\n",
    "\n",
    "for i in range(epochs_number):  \n",
    "    \n",
    "    #TRAIN\n",
    "    #print(\"NEWWWWWW\")\n",
    "    while(env.game.epoch_is_over==0):\n",
    "        \n",
    "        current_player=env.game.get_firstplayer()\n",
    "        stack1=env.game.stack1\n",
    "        stack2=env.game.stack2\n",
    "        #print(\"stack1: \", stack1)\n",
    "        #print(\"stack2: \", stack2)\n",
    "        if(env.game.stack1<= env.game.stack2):\n",
    "            small_stack=env.game.stack1\n",
    "        else:\n",
    "            small_stack=env.game.stack2\n",
    "        #print(\"small_stack: \", small_stack)    \n",
    "        \n",
    "\n",
    "        allowed_actions=[0,1,2]\n",
    "        if(current_player==1):\n",
    "            env.agent.set_action(allowed_actions,None,env.game.get_game_round(), env.game.get_hand_player2(),env.game.get_boardcard())\n",
    "            env.set_opponent_action(env.agent.get_action())\n",
    "            reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action(), small_stack)\n",
    "            \n",
    "            #print(\"opponent action: \", env.agent.get_action())\n",
    "\n",
    "        while(env.game.is_game_over()==0):\n",
    "            #print(\"\\n NEW \")\n",
    "            #print(\"qagent card: \", env.game.hand_player1)\n",
    "            #print(\"board action: \", env.game.boardcard)\n",
    "            #print(\"round : \", env.game.game_round)\n",
    "            state=env.get_state()\n",
    "            qagent.set_state(state)\n",
    "            #print(\"State= \",state)\n",
    "            qagent_action=qagent.explore_action(allowed_actions)\n",
    "            #print(\"qagent action: \", qagent_action)\n",
    "\n",
    "            reward,allowed_actions, new_state=env.step(qagent_action, small_stack)\n",
    "            \n",
    "\n",
    "            if(env.game.is_game_over()==1):\n",
    "                #print(\"results: \",env.game.result)\n",
    "                qagent.update(reward, env.get_actions_hist(),stack1,stack2)\n",
    "                \n",
    "        env.reset_card()\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "\n",
    "    env.reset()\n",
    "    state=env.get_state()\n",
    "    qagent.set_state(state)\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(qagent.qtable)\n",
    "random_agent_qtable=qagent.qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.     1.967 -0.708]\n",
      " [-1.     1.925  0.875]\n",
      " [-1.     1.959  0.668]\n",
      " [-1.     1.812  0.462]\n",
      " [-1.     1.891  0.441]\n",
      " [-1.     1.822  0.832]\n",
      " [-1.     0.    -1.081]\n",
      " [-1.     0.    -0.709]\n",
      " [-1.     0.     0.964]\n",
      " [-1.     1.174  1.279]\n",
      " [-1.     0.505  0.196]\n",
      " [-1.     0.12  -0.304]\n",
      " [-1.     0.352 -0.632]\n",
      " [-1.     1.064  1.037]\n",
      " [-1.     1.04   0.566]\n",
      " [-1.     0.98  -0.057]\n",
      " [-1.     0.8    0.215]\n",
      " [-1.     1.     1.   ]\n",
      " [-1.     1.     1.129]\n",
      " [-1.    -0.842  0.472]\n",
      " [-1.    -0.909  1.   ]\n",
      " [-1.    -0.597  0.283]\n",
      " [-1.     1.     1.042]\n",
      " [-1.     0.514  1.   ]\n",
      " [-1.     0.672  0.913]\n",
      " [-1.     0.33   0.762]\n",
      " [-1.     1.     1.   ]\n",
      " [-0.999  0.     1.994]\n",
      " [-1.     0.    -2.   ]\n",
      " [-1.     0.    -2.   ]\n",
      " [-1.     0.    -1.881]\n",
      " [-0.891  0.     1.757]\n",
      " [-1.     0.    -1.41 ]\n",
      " [-1.     0.    -1.262]\n",
      " [-1.     0.    -1.734]\n",
      " [-0.953  0.     1.915]]\n"
     ]
    }
   ],
   "source": [
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(qagent.qtable[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "\n",
    "ax = sns.heatmap(qagent.qtable[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "for i in range(9):\n",
    "    ax = sns.heatmap(qagent.qtable[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(qagent.qtable[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qAgent vs GreedyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy=GreedyAgent()\n",
    "env=Environment(greedy)\n",
    "envTest=Environment(greedy)\n",
    "qagent=QAgent()\n",
    "\n",
    "\n",
    "for i in range(epochs_number):\n",
    "\n",
    "    #TEST\n",
    "    if(i % evaluate_every == 0):\n",
    "        perf=0\n",
    "        for j in range(test_number):\n",
    "            envTest.reset()\n",
    "            current_player=envTest.game.get_firstplayer()\n",
    "            allowed_actions=[0,1,2]\n",
    "            if(current_player==1):\n",
    "                envTest.agent.set_action(allowed_actions,None,envTest.game.get_game_round(), envTest.game.get_hand_player2(),envTest.game.get_boardcard())\n",
    "                envTest.set_opponent_action(envTest.agent.get_action())\n",
    "                reward,current_player,allowed_actions=envTest.game.step_prime(envTest.agent.get_action())\n",
    "\n",
    "            while(envTest.game.is_game_over()==0):\n",
    "                state=envTest.get_state()\n",
    "                qagent.set_state(state)\n",
    "                qagent_action=qagent.exploit_action(allowed_actions)\n",
    "                reward,allowed_actions, new_state=envTest.step(qagent_action)\n",
    "\n",
    "            if(envTest.game.is_game_over()==1):\n",
    "                perf=perf+reward\n",
    "        qagent.set_perf(float(perf)/test_number)    \n",
    "    \n",
    "    #TRAIN\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    allowed_actions=[0,1,2]\n",
    "    if(current_player==1):\n",
    "        env.agent.set_action(allowed_actions,None,env.game.get_game_round(), env.game.get_hand_player2(),env.game.get_boardcard())\n",
    "        env.set_opponent_action(env.agent.get_action())\n",
    "        reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action())\n",
    "\n",
    "    while(env.game.is_game_over()==0):\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        qagent_action=qagent.explore_action(allowed_actions)\n",
    "        reward,allowed_actions, new_state=env.step(qagent_action)\n",
    "\n",
    "        if(env.game.is_game_over()==1):\n",
    "            qagent.update(reward, env.get_actions_hist())\n",
    "    \n",
    "    env.reset()\n",
    "    state=env.get_state()\n",
    "    qagent.set_state(state)\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(qagent.qtable)\n",
    "random_agent_qtable=qagent.qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(qagent.perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qAgent (trained with a random agent) vs HumanAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "humanAgent=HumanAgent()\n",
    "env=Environment(humanAgent)\n",
    "qagent=QAgent()\n",
    "qagent.set_qtable(random_agent_qtable)\n",
    "\n",
    "print(\"How to play?\\n\\nFor the actions:\\n\\t- 0 : Fold\\n\\t- 1 : Check\\n\\t- 2 : Push\\n\\nFor the cards:\\n\\t- 0 : Jack\\n\\t- 1 : Queen\\n\\t- 2 : King\\n\\n \")\n",
    "for i in range(1):\n",
    "    allowed_actions=[0,1,2]\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    while(env.game.is_game_over()==0):\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        \n",
    "        if (current_player==1):\n",
    "            env.agent.set_action(allowed_actions,None, env.game.get_game_round(), env.game.get_hand_player2(),env.game.get_boardcard())\n",
    "            env.set_opponent_action(env.agent.get_action())\n",
    "            reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action())\n",
    "            if(env.game.is_game_over()==1):\n",
    "                print(\"You loose!! He has a:\", env.game.get_hand_player1(), \"\\n\\n\")\n",
    "        if(env.game.is_game_over()==0):\n",
    "            state=env.get_state()\n",
    "            qagent.set_state(state)\n",
    "            qagent_action=qagent.exploit_action(allowed_actions)\n",
    "            reward,allowed_actions, new_state=env.step(qagent_action)\n",
    "            if(env.game.is_game_over()==1):\n",
    "                if(reward<0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nCongratulation, you win !!!\\n\\n\" )\n",
    "                elif(reward>0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nSorry, you loose !!!\\n\\n\" )\n",
    "                elif(reward==0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nIt's a draw !!!\\n\\n\" )\n",
    "                qagent.update(reward, env.get_actions_hist())\n",
    "            qagent.set_state(new_state)\n",
    "\n",
    "    \n",
    "    env.reset()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qAgent (trained with a greedy agent) vs HumanAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "humanAgent=HumanAgent()\n",
    "env=Environment(humanAgent)\n",
    "qagent=QAgent()\n",
    "qagent.set_qtable(greedy_agent_qtable)\n",
    "\n",
    "    \n",
    "print(\"How to play?\\n\\nFor the actions:\\n\\t- 0 : Fold\\n\\t- 1 : Check\\n\\t- 2 : Push\\n\\nFor the cards:\\n\\t- 0 : Jack\\n\\t- 1 : Queen\\n\\t- 2 : King\\n\\n \")\n",
    "for i in range(1):\n",
    "    allowed_actions=[0,1,2]\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    while(env.game.is_game_over()==0):\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        \n",
    "        if (current_player==1):\n",
    "            env.agent.set_action(allowed_actions,None, env.game.get_game_round(), env.game.get_hand_player2(),env.game.get_boardcard())\n",
    "            env.set_opponent_action(env.agent.get_action())\n",
    "            reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action())\n",
    "            if(env.game.is_game_over()==1):\n",
    "                print(\"You loose!! He has a:\", env.game.get_hand_player1(), \"\\n\\n\")\n",
    "        if(env.game.is_game_over()==0):\n",
    "            state=env.get_state()\n",
    "            qagent.set_state(state)\n",
    "            qagent_action=qagent.exploit_action(allowed_actions)\n",
    "            reward,allowed_actions, new_state=env.step(qagent_action)\n",
    "            if(env.game.is_game_over()==1):\n",
    "                if(reward<0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nCongratulation, you win !!!\\n\\n\" )\n",
    "                elif(reward>0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nSorry, you loose !!!\\n\\n\" )\n",
    "                elif(reward==0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nIt's a draw !!!\\n\\n\" )\n",
    "                qagent.update(reward, env.get_actions_hist())\n",
    "            qagent.set_state(new_state)\n",
    "\n",
    "    \n",
    "    env.reset()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = LeducGame()\n",
    "print(game)\n",
    "game.step_prime(1)\n",
    "print(game)\n",
    "game.step_prime(1)\n",
    "print(game)\n",
    "game.step_prime(1)\n",
    "print(game)\n",
    "game.step_prime(2)\n",
    "print(game)\n",
    "game.step_prime(2)\n",
    "print(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtable={[np.zeros((2,3)), np.zeros((2,3))]}\n",
    "print(qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((5,2,3)) # Make a 10 by 20 by 30 array\n",
    "x[2][0][0]=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
