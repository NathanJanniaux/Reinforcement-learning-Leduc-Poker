{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Game.LeducGame import *\n",
    "from Environment.Environment import *\n",
    "from Opponent_agent.RandAgent import *\n",
    "from Opponent_agent.GreedyAgent import *\n",
    "from Opponent_agent.HumanAgent import *\n",
    "from Qagent.QAgent import *\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "\n",
    "stack_size=5\n",
    "random_agent_qtable=None\n",
    "greedy_agent_qtable=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_number=500\n",
    "evaluate_every=5000\n",
    "test_number=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qAgent vs GreedyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-2.848  2.716  3.494]\n",
      "  [-2.609  2.113  3.704]\n",
      "  [-3.257  2.323  3.13 ]\n",
      "  [-1.72   2.28   1.626]\n",
      "  [-0.95   1.355  2.331]\n",
      "  [-1.355  2.679  2.384]\n",
      "  [-1.72   0.     1.264]\n",
      "  [-0.95   0.     1.619]\n",
      "  [-1.355  0.     0.95 ]\n",
      "  [-0.5    0.     0.6  ]\n",
      "  [ 0.     1.04   0.   ]\n",
      "  [ 0.     0.     2.338]\n",
      "  [ 0.     0.96   0.6  ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [-0.5    0.6    0.   ]\n",
      "  [-0.5    1.14   0.   ]\n",
      "  [-0.95   0.95   0.6  ]\n",
      "  [ 0.     0.6    0.   ]\n",
      "  [ 0.     1.14   0.6  ]\n",
      "  [ 0.     0.4    0.   ]\n",
      "  [ 0.     0.4    0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.6    0.   ]\n",
      "  [ 0.     0.6    0.6  ]\n",
      "  [ 0.     0.     1.14 ]\n",
      "  [-0.5    0.6    0.   ]\n",
      "  [-0.5    0.     0.   ]\n",
      "  [ 0.     0.     0.4  ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.4  ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.4  ]\n",
      "  [ 0.     0.     0.94 ]\n",
      "  [ 0.     0.     0.5  ]\n",
      "  [ 0.     0.     0.   ]]\n",
      "\n",
      " [[ 3.085  2.848  4.517]\n",
      "  [ 3.333  4.519  4.482]\n",
      "  [ 3.259  3.33   5.121]\n",
      "  [ 2.278  3.672  2.439]\n",
      "  [ 2.45   4.294  2.847]\n",
      "  [ 2.745  3.799  4.671]\n",
      "  [ 2.278  0.     2.404]\n",
      "  [ 2.278  0.     2.637]\n",
      "  [ 2.745  0.     1.33 ]\n",
      "  [ 0.4    0.6    0.   ]\n",
      "  [ 0.4    0.85   0.6  ]\n",
      "  [ 0.4    0.     0.6  ]\n",
      "  [ 0.4    1.547  0.6  ]\n",
      "  [ 0.     0.6    1.23 ]\n",
      "  [ 1.084  0.95   2.541]\n",
      "  [ 0.4    0.5    0.75 ]\n",
      "  [ 0.4    0.     1.626]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.6    0.7  ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 0.76   0.     0.   ]\n",
      "  [ 1.376  0.4    0.   ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 0.4    0.5    1.14 ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.4    0.     0.6  ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 0.76   0.     0.   ]\n",
      "  [ 0.76   0.     0.3  ]\n",
      "  [ 0.76   0.     0.3  ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.3  ]\n",
      "  [ 0.4    0.     0.3  ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 0.4    0.     0.7  ]]\n",
      "\n",
      " [[ 3.176  4.25   4.058]\n",
      "  [ 3.333  4.864  5.072]\n",
      "  [ 3.333  4.523  5.483]\n",
      "  [ 2.983  2.609  2.079]\n",
      "  [ 3.46   3.497  3.745]\n",
      "  [ 2.605  3.702  4.861]\n",
      "  [ 2.605  0.     1.835]\n",
      "  [ 2.745  0.     2.587]\n",
      "  [ 2.605  0.     3.004]\n",
      "  [ 0.76   0.     2.209]\n",
      "  [ 1.084  0.     1.626]\n",
      "  [ 1.376  0.4    0.6  ]\n",
      "  [ 0.76   0.95   1.379]\n",
      "  [ 0.76   0.6    0.6  ]\n",
      "  [ 0.76   1.991  2.133]\n",
      "  [ 1.084  0.95   0.6  ]\n",
      "  [ 1.084  1.05   0.2  ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 0.4    0.4    0.   ]\n",
      "  [ 0.     0.4    1.14 ]\n",
      "  [ 0.     0.4    0.6  ]\n",
      "  [ 0.     0.     0.6  ]\n",
      "  [ 0.     0.     0.6  ]\n",
      "  [ 0.4    0.6    0.5  ]\n",
      "  [ 0.     0.6    0.   ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 0.     0.     0.8  ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.76   0.     0.785]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.76   0.     0.5  ]\n",
      "  [ 0.4    0.     0.2  ]\n",
      "  [ 0.76   0.     0.   ]\n",
      "  [ 0.     0.     0.8  ]]\n",
      "\n",
      " [[ 3.91   4.814  3.62 ]\n",
      "  [ 3.863  4.928  5.202]\n",
      "  [ 3.46   5.07   5.205]\n",
      "  [ 2.745  4.347  3.398]\n",
      "  [ 3.562  4.918  4.232]\n",
      "  [ 3.847  4.63   5.623]\n",
      "  [ 3.333  0.     3.456]\n",
      "  [ 3.176  0.     2.035]\n",
      "  [ 2.745  0.     3.688]\n",
      "  [ 0.4    1.626  1.896]\n",
      "  [ 1.084  1.91   2.007]\n",
      "  [ 1.638  0.86   1.14 ]\n",
      "  [ 1.874  1.466  1.652]\n",
      "  [ 0.76   1.14   0.   ]\n",
      "  [ 0.4    1.72   2.311]\n",
      "  [ 1.874  2.303  1.315]\n",
      "  [ 0.76   1.14   0.6  ]\n",
      "  [ 0.     0.     2.457]\n",
      "  [ 0.     0.6    1.14 ]\n",
      "  [ 0.     0.     0.69 ]\n",
      "  [ 0.4    0.     1.626]\n",
      "  [ 0.76   0.95   0.   ]\n",
      "  [ 0.76   0.     0.6  ]\n",
      "  [ 1.084  0.     0.6  ]\n",
      "  [ 0.76   1.455  0.6  ]\n",
      "  [ 0.76   0.     0.   ]\n",
      "  [ 0.     1.14   0.   ]\n",
      "  [ 0.4    0.     0.9  ]\n",
      "  [ 0.4    0.     0.344]\n",
      "  [ 1.084  0.     0.19 ]\n",
      "  [ 0.76   0.     0.271]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.76   0.     0.19 ]\n",
      "  [ 0.76   0.     1.534]\n",
      "  [ 0.76   0.     0.1  ]\n",
      "  [ 0.     0.     0.9  ]]\n",
      "\n",
      " [[ 3.961  5.114  4.602]\n",
      "  [ 3.994  5.14   6.078]\n",
      "  [ 3.988  5.042  5.784]\n",
      "  [ 3.961  4.826  4.734]\n",
      "  [ 3.767  5.089  3.346]\n",
      "  [ 3.606  5.124  6.043]\n",
      "  [ 3.645  0.     1.08 ]\n",
      "  [ 3.46   0.     4.712]\n",
      "  [ 3.46   0.     4.782]\n",
      "  [ 1.638  2.063  1.54 ]\n",
      "  [ 1.874  3.428  1.857]\n",
      "  [ 1.638  2.072  3.675]\n",
      "  [ 2.087  1.71   2.299]\n",
      "  [ 1.638  1.14   1.95 ]\n",
      "  [ 1.638  2.384  0.6  ]\n",
      "  [ 1.376  2.148  2.817]\n",
      "  [ 1.874  1.14   0.6  ]\n",
      "  [ 1.638  1.626  1.14 ]\n",
      "  [ 1.084  0.6    0.6  ]\n",
      "  [ 0.76   1.466  1.026]\n",
      "  [ 1.084  0.     0.6  ]\n",
      "  [ 0.4    0.4    0.54 ]\n",
      "  [ 1.376  0.     0.6  ]\n",
      "  [ 0.4    0.6    2.063]\n",
      "  [ 0.76   1.536  1.626]\n",
      "  [ 1.376  1.536  0.   ]\n",
      "  [ 0.     0.6    0.   ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 1.084  0.     0.   ]\n",
      "  [ 1.874  0.     0.   ]\n",
      "  [ 2.087  0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 1.084  0.     0.5  ]\n",
      "  [ 1.638  0.     1.31 ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 0.4    0.     1.9  ]]\n",
      "\n",
      " [[ 3.742  4.845  4.948]\n",
      "  [ 3.812  4.928  4.526]\n",
      "  [ 3.812  4.923  5.782]\n",
      "  [ 3.333  4.182  4.388]\n",
      "  [ 3.085  4.143  3.205]\n",
      "  [ 3.085  4.35   3.92 ]\n",
      "  [ 2.87   0.     2.788]\n",
      "  [ 2.087  0.     2.422]\n",
      "  [ 2.605  0.     4.218]\n",
      "  [ 0.76   0.     1.896]\n",
      "  [ 2.087  0.85   0.6  ]\n",
      "  [ 1.084  1.683  1.14 ]\n",
      "  [ 1.874  1.809  2.063]\n",
      "  [ 0.     1.545  0.6  ]\n",
      "  [ 1.376  2.276  0.6  ]\n",
      "  [ 1.084  2.333  2.052]\n",
      "  [ 1.874  1.05   0.   ]\n",
      "  [ 0.     0.6    0.6  ]\n",
      "  [ 0.4    0.6    0.   ]\n",
      "  [ 0.     0.     0.6  ]\n",
      "  [ 0.     0.85   0.   ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 0.     0.     0.6  ]\n",
      "  [ 1.376  1.04   0.   ]\n",
      "  [ 0.     1.14   1.626]\n",
      "  [ 0.4    0.6    0.   ]\n",
      "  [ 0.76   0.     0.6  ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.4    0.     0.271]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.76   0.     0.19 ]\n",
      "  [ 0.     0.     0.9  ]\n",
      "  [ 0.76   0.     0.1  ]\n",
      "  [ 0.4    0.     0.991]\n",
      "  [ 0.4    0.     0.1  ]\n",
      "  [ 0.     0.     0.   ]]\n",
      "\n",
      " [[ 3.085  4.345  4.175]\n",
      "  [ 3.176  3.929  3.998]\n",
      "  [ 2.87   3.063  4.268]\n",
      "  [ 1.376  3.81   3.418]\n",
      "  [ 2.983  1.72   2.709]\n",
      "  [ 1.084  3.31   3.52 ]\n",
      "  [ 2.278  0.     1.483]\n",
      "  [ 1.874  0.     1.177]\n",
      "  [ 1.638  0.     2.168]\n",
      "  [ 0.4    0.6    1.32 ]\n",
      "  [ 0.4    0.85   0.2  ]\n",
      "  [ 0.76   0.4    1.773]\n",
      "  [ 0.     0.85   0.6  ]\n",
      "  [ 0.4    0.6    0.   ]\n",
      "  [ 1.084  1.445  1.14 ]\n",
      "  [ 0.     0.     0.6  ]\n",
      "  [ 1.084  0.     0.2  ]\n",
      "  [ 0.     1.14   1.14 ]\n",
      "  [ 1.084  0.     0.   ]\n",
      "  [ 0.4    0.     1.14 ]\n",
      "  [ 0.     0.4    1.14 ]\n",
      "  [ 0.     0.95   0.   ]\n",
      "  [ 0.     0.6    0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.4    0.6    1.14 ]\n",
      "  [ 0.     0.5    0.6  ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.4    0.     0.2  ]\n",
      "  [ 0.     0.     0.38 ]\n",
      "  [ 0.     0.     0.2  ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.76   0.     0.   ]\n",
      "  [ 0.     0.     0.68 ]\n",
      "  [ 0.     0.     0.5  ]\n",
      "  [ 0.     0.     0.   ]]\n",
      "\n",
      " [[ 2.278  3.338  1.056]\n",
      "  [ 1.874  3.856  3.086]\n",
      "  [ 1.084  0.95   3.865]\n",
      "  [ 1.874  2.668  2.7  ]\n",
      "  [ 1.638  1.72   2.102]\n",
      "  [ 1.874  2.681  2.491]\n",
      "  [ 1.376  0.     1.911]\n",
      "  [ 0.     0.     1.173]\n",
      "  [ 1.376  0.     0.95 ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.4    0.86   0.87 ]\n",
      "  [ 0.76   0.5    0.6  ]\n",
      "  [ 1.376  0.     1.14 ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 1.376  0.     0.87 ]\n",
      "  [ 0.     0.     0.3  ]\n",
      "  [ 0.     0.     0.3  ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.4    0.     0.84 ]\n",
      "  [ 0.     0.5    0.   ]\n",
      "  [ 0.     0.76   0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.4    0.6    0.   ]\n",
      "  [ 0.     0.5    0.   ]\n",
      "  [ 0.     0.6    0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.4    0.     0.3  ]\n",
      "  [ 0.4    0.     0.3  ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.4    0.     0.3  ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.76   0.     0.   ]]\n",
      "\n",
      " [[ 0.76   0.5    1.464]\n",
      "  [ 0.     0.5    0.6  ]\n",
      "  [ 1.376  1.355  0.6  ]\n",
      "  [ 0.76   0.5    0.94 ]\n",
      "  [ 0.76   1.355  0.6  ]\n",
      "  [ 0.     0.5    1.04 ]\n",
      "  [ 1.376  0.     0.4  ]\n",
      "  [ 0.4    0.     1.04 ]\n",
      "  [ 1.376  0.     0.5  ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.4    0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 0.4    0.6    0.   ]\n",
      "  [ 0.     0.     0.6  ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.4    0.6  ]\n",
      "  [ 0.4    0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.4  ]\n",
      "  [ 0.     0.     0.   ]\n",
      "  [ 0.     0.     0.   ]]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a78532eda3c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[0mgreedy_agent_qtable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqagent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqtable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m \u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "greedy=GreedyAgent()\n",
    "env=Environment(greedy)\n",
    "envTest=Environment(greedy)\n",
    "qagent=QAgent()\n",
    "\n",
    "\n",
    "for i in range(epochs_number):  \n",
    "    \n",
    "    #TRAIN\n",
    "    #print(\"NEWWWWWW\")\n",
    "    while(env.game.epoch_is_over==0):\n",
    "        \n",
    "        current_player=env.game.get_firstplayer()\n",
    "        stack1=env.game.stack1\n",
    "        stack2=env.game.stack2\n",
    "        #print(\"stack1: \", stack1)\n",
    "        #print(\"stack2: \", stack2)\n",
    "        if(env.game.stack1<= env.game.stack2):\n",
    "            small_stack=env.game.stack1\n",
    "        else:\n",
    "            small_stack=env.game.stack2\n",
    "        #print(\"small_stack: \", small_stack)    \n",
    "        \n",
    "\n",
    "        allowed_actions=[0,1,2]\n",
    "        if(current_player==1):\n",
    "            env.agent.set_action(allowed_actions,None,env.game.get_game_round(), env.game.get_hand_player2(),env.game.get_boardcard())\n",
    "            env.set_opponent_action(env.agent.get_action())\n",
    "            reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action(), small_stack)\n",
    "            \n",
    "            #print(\"opponent action: \", env.agent.get_action())\n",
    "\n",
    "        while(env.game.is_game_over()==0):\n",
    "            #print(\"\\n NEW \")\n",
    "            #print(\"qagent card: \", env.game.hand_player1)\n",
    "            #print(\"board action: \", env.game.boardcard)\n",
    "            #print(\"round : \", env.game.game_round)\n",
    "            state=env.get_state()\n",
    "            qagent.set_state(state)\n",
    "            #print(\"State= \",state)\n",
    "            qagent_action=qagent.explore_action(allowed_actions)\n",
    "            #print(\"qagent action: \", qagent_action)\n",
    "\n",
    "            reward,allowed_actions, new_state=env.step(qagent_action, small_stack)\n",
    "            \n",
    "\n",
    "            if(env.game.is_game_over()==1):\n",
    "                #print(\"results: \",env.game.result)\n",
    "                qagent.update(reward, env.get_actions_hist(),stack1,stack2)\n",
    "                \n",
    "        env.reset_card()\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "\n",
    "    env.reset()\n",
    "    state=env.get_state()\n",
    "    qagent.set_state(state)\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(qagent.qtable)\n",
    "greedy_agent_qtable=qagent.qtable\n",
    "\n",
    "#savetxt('data.csv', data, delimiter=',')\n",
    "np.savetxt('array.csv', [greedy_agent_qtable], delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "tab = pd.DataFrame(qagent.qtable[5])\n",
    "tab_n = tab.div(tab.max(axis=1), axis=0)\n",
    "ax = sns.heatmap(tab_n,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(qagent.qtable[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.DataFrame(qagent.qtable[3], columns=['fold', \"check\",\"push\"])\n",
    "\n",
    "cm = sns.light_palette('blue', as_cmap=True)\n",
    "\n",
    "s = df.style.background_gradient(cmap=cm, low=0, high=1, axis=1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate some example data\n",
    "matrix = np.random.uniform(0,1,(5,5))\n",
    "\n",
    "# plot the matrix as an image with an appropriate colormap\n",
    "plt.imshow(qagent.qtable[1].T, aspect='auto', cmap=\"bwr\")\n",
    "\n",
    "# add the values\n",
    "for (i, j), value in np.ndenumerate(qagent.qtable[1]):\n",
    "    plt.text(i, j, \"%.3f\"%value, va='center', ha='center')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qAgent (trained with a greedy agent) vs HumanAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "humanAgent=HumanAgent()\n",
    "env=Environment(humanAgent)\n",
    "qagent=QAgent()\n",
    "#qagent.set_qtable(greedy_agent_qtable)\n",
    "print(\"How to play?\\n\\nFor the actions:\\n\\t- 0 : Fold\\n\\t- 1 : Check\\n\\t- 2 : Push\\n\\nFor the cards:\\n\\t- 0 : Jack\\n\\t- 1 : Queen\\n\\t- 2 : King\\n\\n \")\n",
    "while(env.game.epoch_is_over==0):\n",
    "    #env.display()\n",
    "    print(\"\\n==NEW GAME==\")\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    stack1=env.game.stack1\n",
    "    stack2=env.game.stack2\n",
    "    #print(\"stack1: \", stack1)\n",
    "    #print(\"stack2: \", stack2)\n",
    "    if(env.game.stack1<= env.game.stack2):\n",
    "        small_stack=env.game.stack1\n",
    "    else:\n",
    "        small_stack=env.game.stack2\n",
    "    #print(\"small_stack: \", small_stack)    \n",
    "\n",
    "\n",
    "    allowed_actions=[0,1,2]\n",
    "\n",
    "    #IF HUMAN AGENT\n",
    "    if(current_player==1):\n",
    "        print(\"Your stack = \",env.game.stack2)\n",
    "        print(\"QAgent stack = \",env.game.stack1)\n",
    "        env.agent.set_action(allowed_actions,None,env.game.get_game_round(), env.game.get_hand_player2(),env.game.get_boardcard())\n",
    "        env.set_opponent_action(env.agent.get_action())\n",
    "        reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action(), small_stack)\n",
    "        if(env.game.is_game_over()==1):\n",
    "            print(\"You loose!! He has a:\", env.game.get_hand_player1(), \"\\n\\n\")\n",
    "\n",
    "        #print(\"opponent action: \", env.agent.get_action())\n",
    "\n",
    "    while(env.game.is_game_over()==0):\n",
    "        #print(\"\\n NEW \")\n",
    "        #print(\"qagent card: \", env.game.hand_player1)\n",
    "        #print(\"board action: \", env.game.boardcard)\n",
    "        #print(\"round : \", env.game.game_round)\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        #print(\"State= \",state)\n",
    "        qagent_action=qagent.exploit_action(allowed_actions, env.game.stack1)\n",
    "        #print(\"qagent action: \", qagent_action)\n",
    "\n",
    "        reward,allowed_actions, new_state=env.step_human(qagent_action, small_stack)\n",
    "\n",
    "\n",
    "        if(env.game.is_game_over()==1):\n",
    "            #print(\"results: \",env.game.result)\n",
    "            if(reward<0):\n",
    "                print(\"His action is: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nCongratulation, you win !!!\\n\\n\" )\n",
    "            elif(reward>0):\n",
    "                print(\"His action is: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nSorry, you loose !!!\\n\\n\" )\n",
    "            elif(reward==0):\n",
    "                print(\"His action is: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nIt's a draw !!!\\n\\n\" )\n",
    "\n",
    "    env.reset_card()\n",
    "    state=env.get_state()\n",
    "    qagent.set_state(state)\n",
    "\n",
    "env.reset()\n",
    "state=env.get_state()\n",
    "qagent.set_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qagent.qtable[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "humanAgent=HumanAgent()\n",
    "env=Environment(humanAgent)\n",
    "qagent=QAgent()\n",
    "qagent.set_qtable(greedy_agent_qtable)\n",
    "\n",
    "    \n",
    "print(\"How to play?\\n\\nFor the actions:\\n\\t- 0 : Fold\\n\\t- 1 : Check\\n\\t- 2 : Push\\n\\nFor the cards:\\n\\t- 0 : Jack\\n\\t- 1 : Queen\\n\\t- 2 : King\\n\\n \")\n",
    "for i in range(1):\n",
    "    allowed_actions=[0,1,2]\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    while(env.game.is_game_over()==0):\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        \n",
    "        if (current_player==1):\n",
    "            env.agent.set_action(allowed_actions,None, env.game.get_game_round(), env.game.get_hand_player2(),env.game.get_boardcard())\n",
    "            env.set_opponent_action(env.agent.get_action())\n",
    "            reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action())\n",
    "            if(env.game.is_game_over()==1):\n",
    "                print(\"You loose!! He has a:\", env.game.get_hand_player1(), \"\\n\\n\")\n",
    "        if(env.game.is_game_over()==0):\n",
    "            state=env.get_state()\n",
    "            qagent.set_state(state)\n",
    "            qagent_action=qagent.exploit_action(allowed_actions)\n",
    "            reward,allowed_actions, new_state=env.step(qagent_action)\n",
    "            if(env.game.is_game_over()==1):\n",
    "                if(reward<0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nCongratulation, you win !!!\\n\\n\" )\n",
    "                elif(reward>0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nSorry, you loose !!!\\n\\n\" )\n",
    "                elif(reward==0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nIt's a draw !!!\\n\\n\" )\n",
    "                qagent.update(reward, env.get_actions_hist())\n",
    "            qagent.set_state(new_state)\n",
    "\n",
    "    \n",
    "    env.reset()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
