{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stack_size=10\n",
    "random_agent_qtable=None\n",
    "greedy_agent_qtable=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeducGame class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LeducGame:\n",
    "    deck = []\n",
    "    actions = [0,1,2] #0 is fold, 1 is check, 2 push\n",
    "    firstplayer=None; #0 if player1 and 1 if player2\n",
    "    hand_player1=0;\n",
    "    hand_player2=0;\n",
    "    boardcard=0;\n",
    "    result=0;\n",
    "    step_number=0\n",
    "    roundGame=0 #0 preflop, 1 postflop\n",
    "    game_round=0\n",
    "    pot=None\n",
    "    stack1=None\n",
    "    stack2=None\n",
    "    lastAction=None\n",
    "    current_player=None\n",
    "    game_is_over=None #0 game is not over, #1 game is over\n",
    "    actions_hist=[]\n",
    "    #inititate a game\n",
    "    def __init__(self):\n",
    "        self.deck = [0,0,1,1,2,2]\n",
    "        \n",
    "        #deal card to game from deck\n",
    "        self.hand_player1=utils.choose_and_remove(self.deck)\n",
    "        self.hand_player2=utils.choose_and_remove(self.deck)\n",
    "        self.boardcard=utils.choose_and_remove(self.deck)\n",
    "        self.result=self.get_result()\n",
    "        self.firstplayer=random.randrange(0,2)\n",
    "        #self.firstplayer=0\n",
    "        self.step_number=0\n",
    "        self.roundGame=0\n",
    "        self.game_round=0\n",
    "        self.pot=0\n",
    "        self.stack1=stack_size\n",
    "        self.stack2=stack_size\n",
    "        self.current_player=self.firstplayer\n",
    "        self.game_is_over=0 #0 not over, 1 over\n",
    "        \n",
    "        self.pot=2\n",
    "        self.stack1=self.stack1-1\n",
    "        self.stack2=self.stack2-1\n",
    "        \n",
    "    #allow to print leduc game state\n",
    "    def __str__(self):\n",
    "        return \"FirstPlayer = {} \\nHand1 = {} \\nHand2 = {} \\nBoard = {} \\nDeck = {}\\nResult = {}\\nStack1={}\\nStack2={}\\nPot={}\\nStep={}\\nRound={}\\nGameIsOver={}\\nCurrent_player{}\\n\\n\".format(self.firstplayer,self.hand_player1,self.hand_player2,self.boardcard,self.deck, self.result,self.stack1,self.stack2,self.pot,self.step_number,self.game_round,self.game_is_over, self.current_player)\n",
    "     \n",
    "    def get_firstplayer(self):\n",
    "        return self.firstplayer\n",
    "        \n",
    "    def get_hand_player1(self):\n",
    "        return self.hand_player1\n",
    "    \n",
    "    def get_hand_player2(self):\n",
    "        return self.hand_player2\n",
    "        \n",
    "    def get_boardcard(self):\n",
    "        return self.boardcard\n",
    "        \n",
    "    def get_current_player(self):\n",
    "        return self.current_player\n",
    "        \n",
    "    def is_game_over(self):\n",
    "        return self.game_is_over\n",
    "    \n",
    "    def get_game_round(self):\n",
    "        return self.game_round\n",
    "        \n",
    "    #result() : \n",
    "    # 0  -> draw\n",
    "    # 1  -> player1 win\n",
    "    #-1  -> player2 win\n",
    "    def get_result(self): #determine the best hand\n",
    "        #Pairs\n",
    "        if (self.hand_player1==self.boardcard):\n",
    "            result=1\n",
    "        elif (self.hand_player2==self.boardcard):\n",
    "            result=-1\n",
    "        #Highest card\n",
    "        elif (self.hand_player1>self.hand_player2):\n",
    "            result=1\n",
    "        elif(self.hand_player1<self.hand_player2):\n",
    "            result=-1\n",
    "        #Draw\n",
    "        else:\n",
    "            result=0\n",
    "        return result    \n",
    "    \n",
    "    def get_allowed_actions(self, action):\n",
    "        if (action==0):\n",
    "            return None\n",
    "        elif (action==1):        \n",
    "            return [0,1,2]\n",
    "        elif (action==2):\n",
    "            return [0, 2]\n",
    "        \n",
    "    def step_prime(self, action):\n",
    "        old_round=self.game_round\n",
    "        gain=0\n",
    "        \n",
    "        #QAGENT\n",
    "        if(self.current_player==0):\n",
    "            if(action==0):\n",
    "                gain=-1\n",
    "                self.game_is_over=1\n",
    "            elif(action==2):\n",
    "                self.stack1=0\n",
    "\n",
    "            #step1\n",
    "            if(self.step_number==0):\n",
    "                if(action==1):\n",
    "                    self.lastAction=1\n",
    "    \n",
    "                if(action==2):\n",
    "                    self.pot=12\n",
    "                    self.lastAction=2\n",
    "                self.step_number=1\n",
    "            #step2        \n",
    "            elif(self.step_number==1):\n",
    "                if(action==1):\n",
    "                    if(self.lastAction==1):\n",
    "                        if(self.game_round==1):\n",
    "                            self.game_is_over=1\n",
    "                            \n",
    "                            if(self.get_result()==1):\n",
    "                                gain=1\n",
    "                            if(self.get_result()==-1):\n",
    "                                gain=-1\n",
    "                            \n",
    "                        self.game_round=1\n",
    "                        self.step_number=0\n",
    "                if(action==2):\n",
    "                    if(self.lastAction==2):\n",
    "                        self.pot=20\n",
    "                        self.game_is_over=1\n",
    "                        \n",
    "                        if(self.get_result()==1):\n",
    "                            gain=10\n",
    "                        if(self.get_result()==-1):\n",
    "                            gain=-10\n",
    "                \n",
    "                            \n",
    "                    if(self.lastAction==1):\n",
    "                        self.pot=12\n",
    "                        self.step_number=2\n",
    "\n",
    "            #step3\n",
    "            elif(self.step_number==2):\n",
    "                if(action==2):\n",
    "                    self.pot=20\n",
    "                    self.game_is_over=1\n",
    "                    \n",
    "                    if(self.get_result()==1):\n",
    "                        gain=10\n",
    "                    if(self.get_result()==-1):\n",
    "                        gain=-10\n",
    "                        \n",
    "        #OPPONENT          \n",
    "        elif(self.current_player==1):\n",
    "            if(action==0):\n",
    "                gain=1\n",
    "                self.game_is_over=1\n",
    "            elif(action==2):\n",
    "                self.stack2=0\n",
    "\n",
    "            #step1\n",
    "            if(self.step_number==0):\n",
    "                if(action==1):\n",
    "                    self.lastAction=1\n",
    "                if(action==2):\n",
    "                    self.pot=12\n",
    "                    self.lastAction=2\n",
    "                self.step_number=1\n",
    "                    \n",
    "            #step2        \n",
    "            elif(self.step_number==1):\n",
    "                if(action==1):\n",
    "                    if(self.lastAction==1):\n",
    "                        if(self.game_round==1):\n",
    "                            self.game_is_over=1\n",
    "                            \n",
    "                            if(self.get_result()==1):\n",
    "                                gain=1\n",
    "                            if(self.get_result()==-1):\n",
    "                                gain=-1\n",
    "                            \n",
    "                        self.game_round=1\n",
    "                        self.step_number=0\n",
    "                if(action==2):\n",
    "                    if(self.lastAction==2):\n",
    "                        self.pot=20\n",
    "                        self.game_is_over=1\n",
    "                        \n",
    "                        if(self.get_result()==1):\n",
    "                            gain=10\n",
    "                        if(self.get_result()==-1):\n",
    "                            gain=-10\n",
    "                            \n",
    "                    if(self.lastAction==1):\n",
    "                        self.pot=12\n",
    "                        self.step_number=2\n",
    "            #step3\n",
    "            elif(self.step_number==2):\n",
    "                if(action==2):\n",
    "                    self.pot=20\n",
    "                    self.game_is_over=1\n",
    "                    \n",
    "                    if(self.get_result()==1):\n",
    "                        gain=10\n",
    "                    if(self.get_result()==-1):\n",
    "                        gain=-10\n",
    "            \n",
    "        allowed_actions= self.get_allowed_actions(action)\n",
    "        #print(\"allowed_actions in step_prime: \", allowed_actions)\n",
    "        #print(\"action= \", action)\n",
    "        #print(self)\n",
    "        if(old_round==self.game_round):\n",
    "            if(self.current_player==0):\n",
    "                self.current_player=1\n",
    "            elif(self.current_player==1):\n",
    "                self.current_player=0\n",
    "            #self.current_player=not(self.current_player)\n",
    "        else:\n",
    "            self.current_player=self.firstplayer   \n",
    "        \n",
    "        return gain,self.current_player, allowed_actions          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    agent=None\n",
    "    game=None\n",
    "    opponent_action=None\n",
    "    actions_hist=[]\n",
    "    \n",
    "    def __init__(self,agent):\n",
    "        self.game=LeducGame()\n",
    "        self.agent=agent\n",
    "        self.actions_hist.clear()\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"{} \\nOpponent_Action = {}\\nStack = {}\".format(self.game,self.agent.get_action(),self.stack)\n",
    "    \n",
    "    def get_actions_hist(self):\n",
    "        return self.actions_hist\n",
    "    \n",
    "    def set_opponent_action(self, action):\n",
    "        self.opponent_action=action\n",
    "    \n",
    "    def get_state(self):\n",
    "       \n",
    "        hand1=self.game.get_hand_player1()\n",
    "        first=self.game.get_firstplayer()\n",
    "        boardcard= self.game.get_boardcard()\n",
    "        \n",
    "        \n",
    "        if self.game.game_round == 0:\n",
    "            if first == 0:\n",
    "                return hand1\n",
    "            elif(first==1 and self.opponent_action==1):\n",
    "                return hand1+3\n",
    "            elif(first==1 and self.opponent_action==2):\n",
    "                return hand1+6\n",
    "            \n",
    "        elif self.game.game_round == 1:\n",
    "            if first == 0:\n",
    "                if hand1==0:\n",
    "                    return boardcard+9\n",
    "                elif hand1== 1:\n",
    "                    return boardcard+12\n",
    "                elif hand1== 2:\n",
    "                    return boardcard+15\n",
    "            elif first == 1:\n",
    "                if (self.opponent_action==1):\n",
    "                    if hand1==0:\n",
    "                        return boardcard+18\n",
    "                    elif hand1==1:\n",
    "                        return boardcard+21\n",
    "                    elif hand1==2:\n",
    "                        return boardcard+24\n",
    "                if(self.opponent_action==2):\n",
    "                    if hand1==0:\n",
    "                        return boardcard+27\n",
    "                    elif hand1==1:\n",
    "                        return boardcard+30\n",
    "                    elif hand1==2:\n",
    "                        return boardcard+33\n",
    "    \n",
    "    def reset(self):\n",
    "        self.game=LeducGame()\n",
    "        self.actions_hist.clear()\n",
    "    \n",
    "    def step(self, qagent_action):\n",
    "        r=0\n",
    "        state=None\n",
    "        last_game_round=self.game.get_game_round()\n",
    "        \n",
    "        self.actions_hist.append([self.get_state(),qagent_action])\n",
    "        r,current_player,allowed_actions=self.game.step_prime(qagent_action)\n",
    "        if(allowed_actions==None):\n",
    "            self.game.game_is_over=1\n",
    "        if(self.game.is_game_over()==0):\n",
    "            if(last_game_round==self.game.get_game_round()):\n",
    "                self.agent.set_action(allowed_actions,qagent_action, self.game.get_game_round(), self.game.get_hand_player2(),self.game.get_boardcard())\n",
    "            else:\n",
    "                self.agent.set_action(allowed_actions,None, self.game.get_game_round(), self.game.get_hand_player2(),self.game.get_boardcard())\n",
    "            \n",
    "            self.opponent_action=self.agent.get_action()\n",
    "            #print( \"agent action\", self.opponent_action)\n",
    "            r,current_player,allowed_actions= self.game.step_prime(self.opponent_action)\n",
    "            if(self.game.is_game_over()==1):\n",
    "                state=None\n",
    "            else:\n",
    "                state=self.get_state()\n",
    "        \n",
    "        return r, allowed_actions, state\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class RandAgent():\n",
    "    \n",
    "    action=None\n",
    "          \n",
    "        \n",
    "    def __init__(self):\n",
    "        #qtable creation\n",
    "        self.set_action([0,1,2], 0,0,0,0)\n",
    "        \n",
    "    def set_action(self,allowed_actions,qagent_action, game_round, hand, boardcard):            \n",
    "        self.action=random.choice(allowed_actions)\n",
    "        \n",
    "    def get_action(self):\n",
    "        return self.action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class GreedyAgent():\n",
    "    \n",
    "    action=None\n",
    "        \n",
    "    def set_action(self,allowed_actions,qagent_action, game_round, hand, boardcard):            \n",
    "        if game_round == 0:\n",
    "            if qagent_action == None:\n",
    "                if hand == 0:\n",
    "                    action_list=[2,0,0,1,1,1,1,1,1,1] #10% of the time it will push, 20% of the time it will fall and 70% of the time it will check \n",
    "                    self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 1:\n",
    "                    action_list=[2,2,2,1,1,1,1,1,1,1] \n",
    "                    self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 2:\n",
    "                    action_list=[2,2,2,2,1,1,1,1,1,1] \n",
    "                    self.action=random.sample(action_list,1)[0]\n",
    "            elif qagent_action == 1:\n",
    "                if hand == 0:\n",
    "                    action_list=[0,0,0,1,1,1,1,1,1,1] \n",
    "                    self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 1:\n",
    "                    self.action=1\n",
    "                elif hand == 2:\n",
    "                    action_list=[2,2,1,1,1,1,1,1,1,1] \n",
    "                    self.action=random.sample(action_list,1)[0]\n",
    "            elif qagent_action == 2:\n",
    "                if hand == 0:\n",
    "                    self.action= 0\n",
    "                elif hand == 1:\n",
    "                    action_list=[2,2,0,0,0,0,0,0,0,0] \n",
    "                    self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 2:\n",
    "                    self.action= 2\n",
    "        elif game_round == 1:\n",
    "            if qagent_action == None:\n",
    "                if hand == 0:\n",
    "                    if boardcard == 0:\n",
    "                        self.action= 2\n",
    "                    elif boardcard == 1:\n",
    "                        action_list=[0,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 2:\n",
    "                        action_list=[0,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 1:\n",
    "                    if boardcard == 0:\n",
    "                        action_list=[2,2,1,1,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 1:\n",
    "                        action_list=[2,2,2,2,2,2,2,2,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 2:\n",
    "                        action_list=[2,2,2,1,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 2:\n",
    "                    if boardcard == 0:\n",
    "                        action_list=[0,2,2,1,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 1:\n",
    "                        action_list=[0,0,2,1,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 2:\n",
    "                        self.action= 2\n",
    "            elif qagent_action == 1:\n",
    "                if hand == 0:\n",
    "                    if boardcard == 0:\n",
    "                        action_list=[2,2,2,2,2,2,2,2,2,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 1:\n",
    "                        action_list=[0,0,1,1,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 2:\n",
    "                        action_list=[0,0,0,0,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 1:\n",
    "                    if boardcard == 0:\n",
    "                        action_list=[0,0,1,1,1,1,1,1,1,2] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 1:\n",
    "                        action_list=[2,2,2,2,2,2,2,2,2,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 2:\n",
    "                        action_list=[0,0,0,0,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 2:\n",
    "                    if boardcard == 0:\n",
    "                        action_list=[0,2,2,2,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 1:\n",
    "                        action_list=[0,0,2,2,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 2:\n",
    "                        action_list=[2,2,2,2,2,2,2,2,2,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "            elif qagent_action == 2:\n",
    "                if hand == 0:\n",
    "                    if boardcard == 0:\n",
    "                        self.action= 2\n",
    "                    elif boardcard == 1:\n",
    "                        self.action= 0\n",
    "                    elif boardcard == 2:\n",
    "                        self.action= 0\n",
    "                elif hand == 1:\n",
    "                    if boardcard == 0:\n",
    "                        self.action= 0\n",
    "                    elif boardcard == 1:\n",
    "                        self.action= 2\n",
    "                    elif boardcard == 2:\n",
    "                        self.action= 0\n",
    "                elif hand == 2:\n",
    "                    if boardcard == 0:\n",
    "                        action_list=[2,2,2,0,0,0,0,0,0,0] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 1:\n",
    "                        action_list=[2,2,0,0,0,0,0,0,0,0] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 2:\n",
    "                        self.action= 2\n",
    "        \n",
    "    def get_action(self):\n",
    "        return self.action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class HumanAgent():\n",
    "    \n",
    "    action=None\n",
    "        \n",
    "    def set_action(self,allowed_actions,qagent_action, game_round, hand, boardcard):            \n",
    "        if (game_round==0):\n",
    "            if (qagent_action==None):\n",
    "                print(\"Your card = \",hand,\"\\n\\n\")\n",
    "            else:\n",
    "                print(\"Your card =\", hand ,\"\\nAction of the QAgent = \",qagent_action,\"\\n\\n\")\n",
    "        elif (game_round==1):\n",
    "            if (qagent_action==None):\n",
    "                print(\"Your card =\", hand ,\"\\nBoardcard = \",boardcard ,\"\\n\\n\")\n",
    "            else:\n",
    "                print(\"Your card =\", hand, \"\\nAction of the QAgent = \",qagent_action,\"\\nBoardcard = \", boardcard,\" \\n\\n\")\n",
    "        self.action = int(input(\"Please enter an action :(0,1 or 2)\\n\"))\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        \n",
    "    def get_action(self):\n",
    "        return self.action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent():\n",
    "    qtable=[]\n",
    " # Agent class definition   state=None\n",
    "    learning_rate=0.1\n",
    "    state=None #0-5\n",
    "    gamma=1\n",
    "    state_number=36\n",
    "    state=None \n",
    "    perf=[]\n",
    "    \n",
    "    def __init__(self):\n",
    "        #qtable creation\n",
    "        self.qtable=np.zeros((self.state_number,3))\n",
    "        self.perf=[]\n",
    "        \n",
    "    #allow to print leduc game state\n",
    "    def __str__(self):\n",
    "        return \"State = {} \\nQTable = {} \\nLearning rate = {}\".format(self.state,self.qtable,self.learning_rate)\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    def explore_action(self, allowed_actions):\n",
    "        action=random.choice(allowed_actions)\n",
    "        return action\n",
    "    \n",
    "    def exploit_action(self, allowed_actions):\n",
    "        #print(\"allowed_actions\",allowed_actions)\n",
    "        #print(\"self.state\", self.state)\n",
    "        #print(\"self.qtable[self.state]\", self.qtable[self.state])\n",
    "        print(\"state: \",self.state )\n",
    "        print(\"liste of actions: \",self.qtable[self.state] )\n",
    "        print(\"action choosed: \", action)\n",
    "        action=utils.get_max_list(self.qtable[self.state], allowed_actions)\n",
    "        return action\n",
    "      \n",
    "    def set_state(self, state):\n",
    "        self.state=state    \n",
    "        \n",
    "    def set_qtable(self,qtable):\n",
    "        self.qtable=qtable\n",
    "        \n",
    "    def set_perf(self,perf):\n",
    "        self.perf.append(perf)\n",
    "\n",
    "    def update(self,reward, actions_hist):\n",
    "        #print(\"UPDATE action= {} \\n reward = {} \\n next_state = {}\\n\".format(action,reward,next_state))\n",
    "        new_value = 0\n",
    "        \n",
    "        #print (\"Update: \\n\")\n",
    "        #print (\"reward = \", reward)\n",
    "        #print (\"actions_hist = \", actions_hist)\n",
    "        if(len(actions_hist)==1):\n",
    "            new_value = (1 - self.learning_rate) * self.qtable[actions_hist[0][0], actions_hist[0][1]] +  self.learning_rate * reward\n",
    "            self.qtable[actions_hist[0][0], actions_hist[0][1]] = new_value\n",
    "            #print(actions_hist)\n",
    "        if(len(actions_hist)==2):\n",
    "            new_value = (1 - self.learning_rate) * self.qtable[actions_hist[1][0], actions_hist[1][1]] +  self.learning_rate * reward\n",
    "            self.qtable[actions_hist[1][0], actions_hist[1][1]] = new_value\n",
    "\n",
    "            back = (1 - self.learning_rate) * self.qtable[actions_hist[0][0], actions_hist[0][1]] +  self.learning_rate * (0 + self.gamma*10)\n",
    "            self.qtable[actions_hist[0][0], actions_hist[0][1]] = back\n",
    "\n",
    "        if(len(actions_hist)==3):\n",
    "            new_value = (1 - self.learning_rate) * self.qtable[actions_hist[2][0], actions_hist[2][1]] +  self.learning_rate * reward\n",
    "            self.qtable[actions_hist[2][0], actions_hist[2][1]] = new_value\n",
    "\n",
    "            back = (1 - self.learning_rate) * self.qtable[actions_hist[1][0], actions_hist[1][1]] +  self.learning_rate * (0 + self.gamma*10)\n",
    "            self.qtable[actions_hist[1][0], actions_hist[1][1]] = back\n",
    "\n",
    "            back_prime = (1 - self.learning_rate) * self.qtable[actions_hist[0][0], actions_hist[0][1]] +  self.learning_rate * (0 + self.gamma*10)\n",
    "            self.qtable[actions_hist[0][0], actions_hist[0][1]] = back_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_number=50000\n",
    "evaluate_every=10000\n",
    "test_number=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qAgent vs RandAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.     7.746 -2.314]\n",
      " [-1.     7.61   1.294]\n",
      " [-1.     6.408  1.075]\n",
      " [-1.     5.766 -2.269]\n",
      " [-1.     6.347  0.965]\n",
      " [-1.     6.648  3.194]\n",
      " [-1.     0.    -3.073]\n",
      " [-1.     0.    -1.804]\n",
      " [-1.     0.     3.489]\n",
      " [-1.     4.875  5.564]\n",
      " [-1.     1.918 -1.946]\n",
      " [-1.     5.715 -2.867]\n",
      " [-1.     2.848 -2.089]\n",
      " [-1.     4.696  5.862]\n",
      " [-1.     2.87   1.059]\n",
      " [-1.     3.52   1.975]\n",
      " [-1.     4.888  3.799]\n",
      " [-1.     3.846  7.182]\n",
      " [-0.85   0.878  4.81 ]\n",
      " [-0.99  -0.606 -6.567]\n",
      " [-0.972 -0.923 -2.78 ]\n",
      " [-0.988 -0.839 -2.787]\n",
      " [-0.942  0.878  4.172]\n",
      " [-0.928  0.24   0.755]\n",
      " [-0.995  0.114  0.443]\n",
      " [-0.975  0.126  2.662]\n",
      " [-0.865  0.833  5.559]\n",
      " [-0.966  0.     9.419]\n",
      " [-0.996  0.    -8.138]\n",
      " [-0.999  0.    -7.624]\n",
      " [-0.991  0.    -6.385]\n",
      " [-0.953  0.     9.818]\n",
      " [-0.998  0.     0.597]\n",
      " [-0.997  0.     2.035]\n",
      " [-1.     0.     3.154]\n",
      " [-0.975  0.     9.114]]\n"
     ]
    }
   ],
   "source": [
    "randAgent=RandAgent()\n",
    "env=Environment(randAgent)\n",
    "qagent=QAgent()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(epochs_number):\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    allowed_actions=[0,1,2]\n",
    "    if(current_player==1):\n",
    "        env.agent.set_action(allowed_actions,0,0,0,0)\n",
    "        env.set_opponent_action(env.agent.get_action())\n",
    "        reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action())\n",
    "\n",
    "    while(env.game.is_game_over()==0):\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        qagent_action=qagent.explore_action(allowed_actions)\n",
    "        reward,allowed_actions, new_state=env.step(qagent_action)\n",
    "\n",
    "        if(env.game.is_game_over()==1):\n",
    "            qagent.update(reward, env.get_actions_hist())\n",
    "\n",
    "    env.reset()\n",
    "    state=env.get_state()\n",
    "    qagent.set_state(state)\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(qagent.qtable)\n",
    "random_agent_qtable=qagent.qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.     5.722 -1.22 ]\n",
      " [-1.     5.403  0.776]\n",
      " [-1.     6.851  2.219]\n",
      " [-1.     8.215  1.009]\n",
      " [-1.     6.497  0.457]\n",
      " [-1.     7.281  0.601]\n",
      " [-1.     0.    -4.288]\n",
      " [-1.     0.    -3.228]\n",
      " [-1.     0.     4.478]\n",
      " [-1.     2.658  6.513]\n",
      " [-1.     3.824 -3.135]\n",
      " [-1.     1.362 -5.229]\n",
      " [-1.     2.027 -4.015]\n",
      " [-1.     5.284  5.057]\n",
      " [-1.     4.156  3.632]\n",
      " [-1.     4.039  1.663]\n",
      " [-1.     4.844  1.416]\n",
      " [-1.     5.219  7.687]\n",
      " [-0.92   0.85   6.71 ]\n",
      " [-0.982 -0.661 -4.408]\n",
      " [-0.984 -0.67  -4.069]\n",
      " [-0.982 -0.655 -3.096]\n",
      " [-0.902  0.935  3.605]\n",
      " [-0.991  0.617  2.9  ]\n",
      " [-0.984  0.324  1.854]\n",
      " [-0.984  0.028  3.903]\n",
      " [-0.833  0.928  5.596]\n",
      " [-0.92   0.     9.722]\n",
      " [-0.999  0.    -5.851]\n",
      " [-1.     0.    -6.993]\n",
      " [-0.998  0.    -5.093]\n",
      " [-0.958  0.     9.892]\n",
      " [-0.993  0.     3.794]\n",
      " [-1.     0.     7.443]\n",
      " [-0.998  0.     3.023]\n",
      " [-0.977  0.     9.419]]\n"
     ]
    }
   ],
   "source": [
    "randAgent=RandAgent()\n",
    "env=Environment(randAgent)\n",
    "envTest=Environment(randAgent)\n",
    "qagent=QAgent()\n",
    "\n",
    "\n",
    "for i in range(epochs_number):\n",
    "\n",
    "    #TEST\n",
    "    if(i % evaluate_every == 0):\n",
    "        perf=0\n",
    "        for j in range(test_number):\n",
    "            envTest.reset()\n",
    "            current_player=envTest.game.get_firstplayer()\n",
    "            allowed_actions=[0,1,2]\n",
    "            if(current_player==1):\n",
    "                envTest.agent.set_action(allowed_actions,None,envTest.game.get_game_round(), envTest.game.get_hand_player2(),envTest.game.get_boardcard())\n",
    "                envTest.set_opponent_action(envTest.agent.get_action())\n",
    "                reward,current_player,allowed_actions=envTest.game.step_prime(envTest.agent.get_action())\n",
    "\n",
    "            while(envTest.game.is_game_over()==0):\n",
    "                state=envTest.get_state()\n",
    "                qagent.set_state(state)\n",
    "                qagent_action=qagent.exploit_action(allowed_actions)\n",
    "                reward,allowed_actions, new_state=envTest.step(qagent_action)\n",
    "\n",
    "            if(envTest.game.is_game_over()==1):\n",
    "                perf=perf+reward\n",
    "        qagent.set_perf(float(perf)/test_number)    \n",
    "    \n",
    "    #TRAIN\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    allowed_actions=[0,1,2]\n",
    "    if(current_player==1):\n",
    "        env.agent.set_action(allowed_actions,0,0,0,0)\n",
    "        env.set_opponent_action(env.agent.get_action())\n",
    "        reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action())\n",
    "\n",
    "    while(env.game.is_game_over()==0):\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        qagent_action=qagent.explore_action(allowed_actions)\n",
    "        reward,allowed_actions, new_state=env.step(qagent_action)\n",
    "\n",
    "        if(env.game.is_game_over()==1):\n",
    "            qagent.update(reward, env.get_actions_hist())\n",
    "    \n",
    "    env.reset()\n",
    "    state=env.get_state()\n",
    "    qagent.set_state(state)\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(qagent.qtable)\n",
    "random_agent_qtable=qagent.qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1dbad566b70>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(qagent.perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qAgent vs GreedyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.      8.733  -0.367]\n",
      " [ -1.      9.405  -1.112]\n",
      " [ -1.      9.266   1.383]\n",
      " [ -1.      9.098  -1.961]\n",
      " [ -1.      8.736  -1.635]\n",
      " [ -1.      7.282   2.033]\n",
      " [ -1.      0.     -5.782]\n",
      " [ -1.      0.     -0.535]\n",
      " [ -1.      0.      3.678]\n",
      " [ -1.      2.937   1.831]\n",
      " [ -1.      4.059  -4.389]\n",
      " [ -1.      1.768  -2.424]\n",
      " [ -1.      2.612  -3.975]\n",
      " [ -1.      1.945   1.815]\n",
      " [ -1.      3.394  -4.279]\n",
      " [ -1.      2.179  -1.35 ]\n",
      " [ -1.      3.551  -2.588]\n",
      " [ -1.      1.      1.   ]\n",
      " [ -1.      1.      1.476]\n",
      " [ -1.     -0.716  -0.274]\n",
      " [ -1.     -0.741   1.   ]\n",
      " [ -1.     -0.484  -0.561]\n",
      " [ -0.997   1.      2.686]\n",
      " [ -1.      0.508   1.   ]\n",
      " [ -1.      0.794   0.917]\n",
      " [ -1.      0.252   0.213]\n",
      " [ -1.      1.      1.   ]\n",
      " [ -0.953   0.      9.797]\n",
      " [ -1.      0.    -10.   ]\n",
      " [ -1.      0.    -10.   ]\n",
      " [ -1.      0.     -9.281]\n",
      " [ -0.613   0.      6.513]\n",
      " [ -1.      0.     -7.436]\n",
      " [ -1.      0.     -5.375]\n",
      " [ -1.      0.     -9.93 ]\n",
      " [ -0.962   0.      9.576]]\n"
     ]
    }
   ],
   "source": [
    "greedyAgent=GreedyAgent()\n",
    "env=Environment(greedyAgent)\n",
    "qagent=QAgent()\n",
    "\n",
    "\n",
    "for i in range(epochs_number):\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    allowed_actions=[0,1,2]\n",
    "    if(current_player==1):\n",
    "        env.agent.set_action(allowed_actions,None,env.game.get_game_round(), env.game.get_hand_player2(),env.game.get_boardcard())\n",
    "        env.set_opponent_action(env.agent.get_action())\n",
    "        reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action())\n",
    "\n",
    "    while(env.game.is_game_over()==0):\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        qagent_action=qagent.explore_action(allowed_actions)\n",
    "        reward,allowed_actions, new_state=env.step(qagent_action)\n",
    "\n",
    "        if(env.game.is_game_over()==1):\n",
    "            qagent.update(reward, env.get_actions_hist())\n",
    "\n",
    "    env.reset()\n",
    "    state=env.get_state()\n",
    "    qagent.set_state(state)\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(qagent.qtable)\n",
    "random_agent_qtable=qagent.qtable\n",
    "\n",
    "greedy_agent_qtable=qagent.qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.      8.359  -1.525]\n",
      " [ -1.      9.149  -0.341]\n",
      " [ -1.      8.966   2.021]\n",
      " [ -1.      7.867  -1.62 ]\n",
      " [ -1.      7.66   -1.402]\n",
      " [ -1.      7.895   1.077]\n",
      " [ -1.      0.     -3.709]\n",
      " [ -1.      0.     -2.711]\n",
      " [ -1.      0.      4.833]\n",
      " [ -1.      1.281   1.577]\n",
      " [ -1.      2.573  -4.521]\n",
      " [ -1.      2.399  -3.359]\n",
      " [ -1.      3.175  -4.285]\n",
      " [ -1.      1.887   2.985]\n",
      " [ -1.      2.525  -1.839]\n",
      " [ -1.      2.994  -0.016]\n",
      " [ -1.      3.807  -2.382]\n",
      " [ -1.      1.      1.   ]\n",
      " [ -1.      1.      2.483]\n",
      " [ -1.     -0.709   0.246]\n",
      " [ -1.     -0.867   1.   ]\n",
      " [ -1.     -0.664  -0.533]\n",
      " [ -0.999   0.999   1.658]\n",
      " [ -1.      0.501   1.   ]\n",
      " [ -1.      0.645   0.956]\n",
      " [ -1.      0.38   -0.49 ]\n",
      " [ -1.      1.      1.   ]\n",
      " [ -0.987   0.      9.818]\n",
      " [ -1.      0.     -9.999]\n",
      " [ -1.      0.    -10.   ]\n",
      " [ -1.      0.     -9.566]\n",
      " [ -0.613   0.      6.862]\n",
      " [ -1.      0.     -8.299]\n",
      " [ -1.      0.     -5.286]\n",
      " [ -1.      0.     -9.3  ]\n",
      " [ -0.948   0.      9.114]]\n"
     ]
    }
   ],
   "source": [
    "greedy=GreedyAgent()\n",
    "env=Environment(greedy)\n",
    "envTest=Environment(greedy)\n",
    "qagent=QAgent()\n",
    "\n",
    "\n",
    "for i in range(epochs_number):\n",
    "\n",
    "    #TEST\n",
    "    if(i % evaluate_every == 0):\n",
    "        perf=0\n",
    "        for j in range(test_number):\n",
    "            envTest.reset()\n",
    "            current_player=envTest.game.get_firstplayer()\n",
    "            allowed_actions=[0,1,2]\n",
    "            if(current_player==1):\n",
    "                envTest.agent.set_action(allowed_actions,None,envTest.game.get_game_round(), envTest.game.get_hand_player2(),envTest.game.get_boardcard())\n",
    "                envTest.set_opponent_action(envTest.agent.get_action())\n",
    "                reward,current_player,allowed_actions=envTest.game.step_prime(envTest.agent.get_action())\n",
    "\n",
    "            while(envTest.game.is_game_over()==0):\n",
    "                state=envTest.get_state()\n",
    "                qagent.set_state(state)\n",
    "                qagent_action=qagent.exploit_action(allowed_actions)\n",
    "                reward,allowed_actions, new_state=envTest.step(qagent_action)\n",
    "\n",
    "            if(envTest.game.is_game_over()==1):\n",
    "                perf=perf+reward\n",
    "        qagent.set_perf(float(perf)/test_number)    \n",
    "    \n",
    "    #TRAIN\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    allowed_actions=[0,1,2]\n",
    "    if(current_player==1):\n",
    "        env.agent.set_action(allowed_actions,None,env.game.get_game_round(), env.game.get_hand_player2(),env.game.get_boardcard())\n",
    "        env.set_opponent_action(env.agent.get_action())\n",
    "        reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action())\n",
    "\n",
    "    while(env.game.is_game_over()==0):\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        qagent_action=qagent.explore_action(allowed_actions)\n",
    "        reward,allowed_actions, new_state=env.step(qagent_action)\n",
    "\n",
    "        if(env.game.is_game_over()==1):\n",
    "            qagent.update(reward, env.get_actions_hist())\n",
    "    \n",
    "    env.reset()\n",
    "    state=env.get_state()\n",
    "    qagent.set_state(state)\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(qagent.qtable)\n",
    "random_agent_qtable=qagent.qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1dbad8424e0>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(qagent.perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qAgent (trained with a random agent) vs HumanAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to play?\n",
      "\n",
      "For the actions:\n",
      "\t- 0 : Fold\n",
      "\t- 1 : Check\n",
      "\t- 2 : Push\n",
      "\n",
      "For the cards:\n",
      "\t- 0 : Jack\n",
      "\t- 1 : Queen\n",
      "\t- 2 : King\n",
      "\n",
      " \n",
      "Your card =  1 \n",
      "\n",
      "\n",
      "Please enter an action :(0,1 or 2)\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "You loose!! He has a: 0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "humanAgent=HumanAgent()\n",
    "env=Environment(humanAgent)\n",
    "qagent=QAgent()\n",
    "qagent.set_qtable(random_agent_qtable)\n",
    "\n",
    "print(\"How to play?\\n\\nFor the actions:\\n\\t- 0 : Fold\\n\\t- 1 : Check\\n\\t- 2 : Push\\n\\nFor the cards:\\n\\t- 0 : Jack\\n\\t- 1 : Queen\\n\\t- 2 : King\\n\\n \")\n",
    "for i in range(1):\n",
    "    allowed_actions=[0,1,2]\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    while(env.game.is_game_over()==0):\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        \n",
    "        if (current_player==1):\n",
    "            env.agent.set_action(allowed_actions,None, env.game.get_game_round(), env.game.get_hand_player2(),env.game.get_boardcard())\n",
    "            env.set_opponent_action(env.agent.get_action())\n",
    "            reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action())\n",
    "            if(env.game.is_game_over()==1):\n",
    "                print(\"You loose!! He has a:\", env.game.get_hand_player1(), \"\\n\\n\")\n",
    "        if(env.game.is_game_over()==0):\n",
    "            state=env.get_state()\n",
    "            qagent.set_state(state)\n",
    "            qagent_action=qagent.exploit_action(allowed_actions)\n",
    "            reward,allowed_actions, new_state=env.step(qagent_action)\n",
    "            if(env.game.is_game_over()==1):\n",
    "                if(reward<0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nCongratulation, you win !!!\\n\\n\" )\n",
    "                elif(reward>0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nSorry, you loose !!!\\n\\n\" )\n",
    "                elif(reward==0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nIt's a draw !!!\\n\\n\" )\n",
    "                qagent.update(reward, env.get_actions_hist())\n",
    "            qagent.set_state(new_state)\n",
    "\n",
    "    \n",
    "    env.reset()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qAgent (trained with a greedy agent) vs HumanAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to play?\n",
      "\n",
      "For the actions:\n",
      "\t- 0 : Fold\n",
      "\t- 1 : Check\n",
      "\t- 2 : Push\n",
      "\n",
      "For the cards:\n",
      "\t- 0 : Jack\n",
      "\t- 1 : Queen\n",
      "\t- 2 : King\n",
      "\n",
      " \n",
      "Your card = 1 \n",
      "Action of the QAgent =  1 \n",
      "\n",
      "\n",
      "Please enter an action :(0,1 or 2)\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "His action was:  1 \n",
      "He has a:  2 \n",
      "Sorry, you loose !!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "humanAgent=HumanAgent()\n",
    "env=Environment(humanAgent)\n",
    "qagent=QAgent()\n",
    "qagent.set_qtable(greedy_agent_qtable)\n",
    "\n",
    "    \n",
    "print(\"How to play?\\n\\nFor the actions:\\n\\t- 0 : Fold\\n\\t- 1 : Check\\n\\t- 2 : Push\\n\\nFor the cards:\\n\\t- 0 : Jack\\n\\t- 1 : Queen\\n\\t- 2 : King\\n\\n \")\n",
    "for i in range(1):\n",
    "    allowed_actions=[0,1,2]\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    while(env.game.is_game_over()==0):\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        \n",
    "        if (current_player==1):\n",
    "            env.agent.set_action(allowed_actions,None, env.game.get_game_round(), env.game.get_hand_player2(),env.game.get_boardcard())\n",
    "            env.set_opponent_action(env.agent.get_action())\n",
    "            reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action())\n",
    "            if(env.game.is_game_over()==1):\n",
    "                print(\"You loose!! He has a:\", env.game.get_hand_player1(), \"\\n\\n\")\n",
    "        if(env.game.is_game_over()==0):\n",
    "            state=env.get_state()\n",
    "            qagent.set_state(state)\n",
    "            qagent_action=qagent.exploit_action(allowed_actions)\n",
    "            reward,allowed_actions, new_state=env.step(qagent_action)\n",
    "            if(env.game.is_game_over()==1):\n",
    "                if(reward<0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nCongratulation, you win !!!\\n\\n\" )\n",
    "                elif(reward>0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nSorry, you loose !!!\\n\\n\" )\n",
    "                elif(reward==0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nIt's a draw !!!\\n\\n\" )\n",
    "                qagent.update(reward, env.get_actions_hist())\n",
    "            qagent.set_state(new_state)\n",
    "\n",
    "    \n",
    "    env.reset()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
