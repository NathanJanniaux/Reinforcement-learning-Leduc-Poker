{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stack_size=10\n",
    "random_agent_qtable=None\n",
    "greedy_agent_qtable=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeducGame class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LeducGame:\n",
    "    deck = []\n",
    "    actions = [0,1,2] #0 is fold, 1 is check, 2 push\n",
    "    firstplayer=None; #0 if player1 and 1 if player2\n",
    "    hand_player1=0;\n",
    "    hand_player2=0;\n",
    "    boardcard=0;\n",
    "    result=0;\n",
    "    step_number=0\n",
    "    roundGame=0 #0 preflop, 1 postflop\n",
    "    game_round=0\n",
    "    pot=None\n",
    "    stack1=None\n",
    "    stack2=None\n",
    "    lastAction=None\n",
    "    current_player=None\n",
    "    game_is_over=None #0 game is not over, #1 game is over\n",
    "    actions_hist=[]\n",
    "    #inititate a game\n",
    "    def __init__(self):\n",
    "        self.deck = [0,0,1,1,2,2]\n",
    "        \n",
    "        #deal card to game from deck\n",
    "        self.hand_player1=utils.choose_and_remove(self.deck)\n",
    "        self.hand_player2=utils.choose_and_remove(self.deck)\n",
    "        self.boardcard=utils.choose_and_remove(self.deck)\n",
    "        self.result=self.get_result()\n",
    "        self.firstplayer=random.randrange(0,2)\n",
    "        #self.firstplayer=0\n",
    "        self.step_number=0\n",
    "        self.roundGame=0\n",
    "        self.game_round=0\n",
    "        self.pot=0\n",
    "        self.stack1=stack_size\n",
    "        self.stack2=stack_size\n",
    "        self.current_player=self.firstplayer\n",
    "        self.game_is_over=0 #0 not over, 1 over\n",
    "        \n",
    "        self.pot=2\n",
    "        self.stack1=self.stack1-1\n",
    "        self.stack2=self.stack2-1\n",
    "        \n",
    "    #allow to print leduc game state\n",
    "    def __str__(self):\n",
    "        return \"FirstPlayer = {} \\nHand1 = {} \\nHand2 = {} \\nBoard = {} \\nDeck = {}\\nResult = {}\\nStack1={}\\nStack2={}\\nPot={}\\nStep={}\\nRound={}\\nGameIsOver={}\\nCurrent_player{}\\n\\n\".format(self.firstplayer,self.hand_player1,self.hand_player2,self.boardcard,self.deck, self.result,self.stack1,self.stack2,self.pot,self.step_number,self.game_round,self.game_is_over, self.current_player)\n",
    "     \n",
    "    def get_firstplayer(self):\n",
    "        return self.firstplayer\n",
    "        \n",
    "    def get_hand_player1(self):\n",
    "        return self.hand_player1\n",
    "    \n",
    "    def get_hand_player2(self):\n",
    "        return self.hand_player2\n",
    "        \n",
    "    def get_boardcard(self):\n",
    "        return self.boardcard\n",
    "        \n",
    "    def get_current_player(self):\n",
    "        return self.current_player\n",
    "        \n",
    "    def is_game_over(self):\n",
    "        return self.game_is_over\n",
    "    \n",
    "    def get_game_round(self):\n",
    "        return self.game_round\n",
    "        \n",
    "    #result() : \n",
    "    # 0  -> draw\n",
    "    # 1  -> player1 win\n",
    "    #-1  -> player2 win\n",
    "    def get_result(self): #determine the best hand\n",
    "        #Pairs\n",
    "        if (self.hand_player1==self.boardcard):\n",
    "            result=1\n",
    "        elif (self.hand_player2==self.boardcard):\n",
    "            result=-1\n",
    "        #Highest card\n",
    "        elif (self.hand_player1>self.hand_player2):\n",
    "            result=1\n",
    "        elif(self.hand_player1<self.hand_player2):\n",
    "            result=-1\n",
    "        #Draw\n",
    "        else:\n",
    "            result=0\n",
    "        return result    \n",
    "    \n",
    "    def get_allowed_actions(self, action):\n",
    "        if (action==0):\n",
    "            return None\n",
    "        elif (action==1):        \n",
    "            return [0,1,2]\n",
    "        elif (action==2):\n",
    "            return [0, 2]\n",
    "        \n",
    "    def step_prime(self, action):\n",
    "        old_round=self.game_round\n",
    "        gain=0\n",
    "        \n",
    "        #QAGENT\n",
    "        if(self.current_player==0):\n",
    "            if(action==0):\n",
    "                gain=-1\n",
    "                self.game_is_over=1\n",
    "            elif(action==2):\n",
    "                self.stack1=0\n",
    "\n",
    "            #step1\n",
    "            if(self.step_number==0):\n",
    "                if(action==1):\n",
    "                    self.lastAction=1\n",
    "    \n",
    "                if(action==2):\n",
    "                    self.pot=12\n",
    "                    self.lastAction=2\n",
    "                self.step_number=1\n",
    "            #step2        \n",
    "            elif(self.step_number==1):\n",
    "                if(action==1):\n",
    "                    if(self.lastAction==1):\n",
    "                        if(self.game_round==1):\n",
    "                            self.game_is_over=1\n",
    "                            \n",
    "                            if(self.get_result()==1):\n",
    "                                gain=1\n",
    "                            if(self.get_result()==-1):\n",
    "                                gain=-1\n",
    "                            \n",
    "                        self.game_round=1\n",
    "                        self.step_number=0\n",
    "                if(action==2):\n",
    "                    if(self.lastAction==2):\n",
    "                        self.pot=20\n",
    "                        self.game_is_over=1\n",
    "                        \n",
    "                        if(self.get_result()==1):\n",
    "                            gain=10\n",
    "                        if(self.get_result()==-1):\n",
    "                            gain=-10\n",
    "                \n",
    "                            \n",
    "                    if(self.lastAction==1):\n",
    "                        self.pot=12\n",
    "                        self.step_number=2\n",
    "\n",
    "            #step3\n",
    "            elif(self.step_number==2):\n",
    "                if(action==2):\n",
    "                    self.pot=20\n",
    "                    self.game_is_over=1\n",
    "                    \n",
    "                    if(self.get_result()==1):\n",
    "                        gain=10\n",
    "                    if(self.get_result()==-1):\n",
    "                        gain=-10\n",
    "                        \n",
    "        #OPPONENT          \n",
    "        elif(self.current_player==1):\n",
    "            if(action==0):\n",
    "                gain=1\n",
    "                self.game_is_over=1\n",
    "            elif(action==2):\n",
    "                self.stack2=0\n",
    "\n",
    "            #step1\n",
    "            if(self.step_number==0):\n",
    "                if(action==1):\n",
    "                    self.lastAction=1\n",
    "                if(action==2):\n",
    "                    self.pot=12\n",
    "                    self.lastAction=2\n",
    "                self.step_number=1\n",
    "                    \n",
    "            #step2        \n",
    "            elif(self.step_number==1):\n",
    "                if(action==1):\n",
    "                    if(self.lastAction==1):\n",
    "                        if(self.game_round==1):\n",
    "                            self.game_is_over=1\n",
    "                            \n",
    "                            if(self.get_result()==1):\n",
    "                                gain=1\n",
    "                            if(self.get_result()==-1):\n",
    "                                gain=-1\n",
    "                            \n",
    "                        self.game_round=1\n",
    "                        self.step_number=0\n",
    "                if(action==2):\n",
    "                    if(self.lastAction==2):\n",
    "                        self.pot=20\n",
    "                        self.game_is_over=1\n",
    "                        \n",
    "                        if(self.get_result()==1):\n",
    "                            gain=10\n",
    "                        if(self.get_result()==-1):\n",
    "                            gain=-10\n",
    "                            \n",
    "                    if(self.lastAction==1):\n",
    "                        self.pot=12\n",
    "                        self.step_number=2\n",
    "            #step3\n",
    "            elif(self.step_number==2):\n",
    "                if(action==2):\n",
    "                    self.pot=20\n",
    "                    self.game_is_over=1\n",
    "                    \n",
    "                    if(self.get_result()==1):\n",
    "                        gain=10\n",
    "                    if(self.get_result()==-1):\n",
    "                        gain=-10\n",
    "            \n",
    "        allowed_actions= self.get_allowed_actions(action)\n",
    "        #print(\"allowed_actions in step_prime: \", allowed_actions)\n",
    "        #print(\"action= \", action)\n",
    "        #print(self)\n",
    "        if(old_round==self.game_round):\n",
    "            if(self.current_player==0):\n",
    "                self.current_player=1\n",
    "            elif(self.current_player==1):\n",
    "                self.current_player=0\n",
    "            #self.current_player=not(self.current_player)\n",
    "        else:\n",
    "            self.current_player=self.firstplayer   \n",
    "        \n",
    "        return gain,self.current_player, allowed_actions          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    agent=None\n",
    "    game=None\n",
    "    opponent_action=None\n",
    "    actions_hist=[]\n",
    "    \n",
    "    def __init__(self,agent):\n",
    "        self.game=LeducGame()\n",
    "        self.agent=agent\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"{} \\nOpponent_Action = {}\\nStack = {}\".format(self.game,self.agent.get_action(),self.stack)\n",
    "    \n",
    "    def get_actions_hist(self):\n",
    "        return self.actions_hist\n",
    "    \n",
    "    def set_opponent_action(self, action):\n",
    "        self.opponent_action=action\n",
    "    \n",
    "    def get_state(self):\n",
    "        hand1=self.game.get_hand_player1()\n",
    "        first=self.game.get_firstplayer()\n",
    "        boardcard= self.game.get_boardcard()\n",
    "        \n",
    "        if self.game.game_round == 0:\n",
    "            if first is 0:\n",
    "                return hand1\n",
    "            elif(first==1 and self.opponent_action==1):\n",
    "                return hand1+3\n",
    "            elif(first==1 and self.opponent_action==2):\n",
    "                return hand1+6\n",
    "            \n",
    "        elif self.game.game_round == 1:\n",
    "            if first is 0:\n",
    "                if hand1==0:\n",
    "                    return boardcard+9\n",
    "                elif hand1== 1:\n",
    "                    return boardcard+12\n",
    "                elif hand1== 2:\n",
    "                    return boardcard+15\n",
    "            else:\n",
    "                if (self.opponent_action==1):\n",
    "                    if hand1==0:\n",
    "                        return boardcard+18\n",
    "                    elif hand1==1:\n",
    "                        return boardcard+21\n",
    "                    elif hand1==2:\n",
    "                        return boardcard+24\n",
    "                if(self.opponent_action==2):\n",
    "                    if hand1==0:\n",
    "                        return boardcard+27\n",
    "                    elif hand1==1:\n",
    "                        return boardcard+30\n",
    "                    elif hand1==2:\n",
    "                        return boardcard+33\n",
    "    \n",
    "    def reset(self):\n",
    "        self.game=LeducGame()\n",
    "        self.actions_hist=[]\n",
    "    \n",
    "    def step(self, qagent_action):\n",
    "        r=0\n",
    "        state=None\n",
    "        last_game_round=self.game.get_game_round()\n",
    "        self.actions_hist.append([self.get_state(),qagent_action])\n",
    "        r,current_player,allowed_actions=self.game.step_prime(qagent_action)\n",
    "        if(allowed_actions==None):\n",
    "            self.game.game_is_over=1\n",
    "        if(self.game.is_game_over()==0):\n",
    "            if(last_game_round==self.game.get_game_round()):\n",
    "                self.agent.set_action(allowed_actions,qagent_action, self.game.get_game_round(), self.game.get_hand_player2(),self.game.get_boardcard())\n",
    "            else:\n",
    "                self.agent.set_action(allowed_actions,None, self.game.get_game_round(), self.game.get_hand_player2(),self.game.get_boardcard())\n",
    "            self.opponent_action=self.agent.get_action()\n",
    "            #print( \"agent action\", self.opponent_action)\n",
    "            r,current_player,allowed_actions= self.game.step_prime(self.opponent_action)\n",
    "            if(self.game.is_game_over()==1):\n",
    "                state=None\n",
    "            else:\n",
    "                state=self.get_state()\n",
    "        \n",
    "        return r, allowed_actions, state\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class RandAgent():\n",
    "    \n",
    "    action=None\n",
    "          \n",
    "        \n",
    "    def __init__(self):\n",
    "        #qtable creation\n",
    "        self.set_action([0,1,2], 0,0,0,0)\n",
    "        \n",
    "    def set_action(self,allowed_actions,qagent_action, game_round, hand, boardcard):            \n",
    "        self.action=random.choice(allowed_actions)\n",
    "        \n",
    "    def get_action(self):\n",
    "        return self.action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class GreedyAgent():\n",
    "    \n",
    "    action=None\n",
    "        \n",
    "    def set_action(self,allowed_actions,qagent_action, game_round, hand, boardcard):            \n",
    "        if game_round == 0:\n",
    "            if qagent_action == None:\n",
    "                if hand == 0:\n",
    "                    action_list=[2,0,0,1,1,1,1,1,1,1] #10% of the time it will push, 20% of the time it will fall and 70% of the time it will check \n",
    "                    self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 1:\n",
    "                    action_list=[2,2,2,1,1,1,1,1,1,1] \n",
    "                    self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 2:\n",
    "                    action_list=[2,2,2,2,1,1,1,1,1,1] \n",
    "                    self.action=random.sample(action_list,1)[0]\n",
    "            elif qagent_action == 1:\n",
    "                if hand == 0:\n",
    "                    action_list=[0,0,0,1,1,1,1,1,1,1] \n",
    "                    self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 1:\n",
    "                    self.action=1\n",
    "                elif hand == 2:\n",
    "                    action_list=[2,2,1,1,1,1,1,1,1,1] \n",
    "                    self.action=random.sample(action_list,1)[0]\n",
    "            elif qagent_action == 2:\n",
    "                if hand == 0:\n",
    "                    self.action= 0\n",
    "                elif hand == 1:\n",
    "                    action_list=[2,2,0,0,0,0,0,0,0,0] \n",
    "                    self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 2:\n",
    "                    self.action= 2\n",
    "        elif game_round == 1:\n",
    "            if qagent_action == None:\n",
    "                if hand == 0:\n",
    "                    if boardcard == 0:\n",
    "                        self.action= 2\n",
    "                    elif boardcard == 1:\n",
    "                        action_list=[0,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 2:\n",
    "                        action_list=[0,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 1:\n",
    "                    if boardcard == 0:\n",
    "                        action_list=[2,2,1,1,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 1:\n",
    "                        action_list=[2,2,2,2,2,2,2,2,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 2:\n",
    "                        action_list=[2,2,2,1,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 2:\n",
    "                    if boardcard == 0:\n",
    "                        action_list=[0,2,2,1,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 1:\n",
    "                        action_list=[0,0,2,1,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 2:\n",
    "                        self.action= 2\n",
    "            elif qagent_action == 1:\n",
    "                if hand == 0:\n",
    "                    if boardcard == 0:\n",
    "                        action_list=[2,2,2,2,2,2,2,2,2,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 1:\n",
    "                        action_list=[0,0,1,1,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 2:\n",
    "                        action_list=[0,0,0,0,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 1:\n",
    "                    if boardcard == 0:\n",
    "                        action_list=[0,0,1,1,1,1,1,1,1,2] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 1:\n",
    "                        action_list=[2,2,2,2,2,2,2,2,2,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 2:\n",
    "                        action_list=[0,0,0,0,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                elif hand == 2:\n",
    "                    if boardcard == 0:\n",
    "                        action_list=[0,2,2,2,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 1:\n",
    "                        action_list=[0,0,2,2,1,1,1,1,1,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 2:\n",
    "                        action_list=[2,2,2,2,2,2,2,2,2,1] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "            elif qagent_action == 2:\n",
    "                if hand == 0:\n",
    "                    if boardcard == 0:\n",
    "                        self.action= 2\n",
    "                    elif boardcard == 1:\n",
    "                        self.action= 0\n",
    "                    elif boardcard == 2:\n",
    "                        self.action= 0\n",
    "                elif hand == 1:\n",
    "                    if boardcard == 0:\n",
    "                        self.action= 0\n",
    "                    elif boardcard == 1:\n",
    "                        self.action= 2\n",
    "                    elif boardcard == 2:\n",
    "                        self.action= 0\n",
    "                elif hand == 2:\n",
    "                    if boardcard == 0:\n",
    "                        action_list=[2,2,2,0,0,0,0,0,0,0] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 1:\n",
    "                        action_list=[2,2,0,0,0,0,0,0,0,0] \n",
    "                        self.action=random.sample(action_list,1)[0]\n",
    "                    elif boardcard == 2:\n",
    "                        self.action= 2\n",
    "        \n",
    "    def get_action(self):\n",
    "        return self.action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class HumanAgent():\n",
    "    \n",
    "    action=None\n",
    "        \n",
    "    def set_action(self,allowed_actions,qagent_action, game_round, hand, boardcard):            \n",
    "        if (game_round==0):\n",
    "            if (qagent_action==None):\n",
    "                print(\"Your card = \",hand,\"\\n\\n\")\n",
    "            else:\n",
    "                print(\"Your card =\", hand ,\"\\nAction of the QAgent = \",qagent_action,\"\\n\\n\")\n",
    "        elif (game_round==1):\n",
    "            if (qagent_action==None):\n",
    "                print(\"Your card =\", hand ,\"\\nBoardcard = \",boardcard ,\"\\n\\n\")\n",
    "            else:\n",
    "                print(\"Your card =\", hand, \"\\nAction of the QAgent = \",qagent_action,\"\\nBoardcard = \", boardcard,\" \\n\\n\")\n",
    "        self.action = int(input(\"Please enter an action :(0,1 or 2)\\n\"))\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        \n",
    "    def get_action(self):\n",
    "        return self.action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent():\n",
    "    qtable=[]\n",
    " # Agent class definition   state=None\n",
    "    learning_rate=0.1\n",
    "    \n",
    "    state=None #0-5\n",
    "    gamma=1\n",
    "    state_number=36\n",
    "    state=None \n",
    "    perf=[]\n",
    "    \n",
    "    def __init__(self):\n",
    "        #qtable creation\n",
    "        self.qtable=np.zeros((self.state_number,3))\n",
    "        self.perf=[]\n",
    "        \n",
    "    #allow to print leduc game state\n",
    "    def __str__(self):\n",
    "        return \"State = {} \\nQTable = {} \\nLearning rate = {}\".format(self.state,self.qtable,self.learning_rate)\n",
    "    \n",
    "    def explore_action(self, allowed_actions):\n",
    "        action=random.choice(allowed_actions)\n",
    "        return action\n",
    "    \n",
    "    def exploit_action(self, allowed_actions):\n",
    "        print(\"allowed_actions= \", allowed_actions)\n",
    "        action=utils.get_max_list(self.qtable[self.state], allowed_actions)\n",
    "        return action\n",
    "      \n",
    "    def set_state(self, state):\n",
    "        self.state=state    \n",
    "        \n",
    "    def set_qtable(self,qtable):\n",
    "        self.qtable=qtable\n",
    "        \n",
    "    def set_perf(self,perf):\n",
    "        self.perf.append(perf)\n",
    "\n",
    "    def update(self,reward, actions_hist):\n",
    "        #print(\"UPDATE action= {} \\n reward = {} \\n next_state = {}\\n\".format(action,reward,next_state))\n",
    "        new_value = 0\n",
    "        \n",
    "        #print (\"Update: \\n\")\n",
    "        #print (\"reward = \", reward)\n",
    "        #print (\"actions_hist = \", actions_hist)\n",
    "        if(len(actions_hist)==1):\n",
    "            new_value = (1 - self.learning_rate) * self.qtable[actions_hist[0][0], actions_hist[0][1]] +  self.learning_rate * reward\n",
    "            self.qtable[actions_hist[0][0], actions_hist[0][1]] = new_value\n",
    "            #print(actions_hist)\n",
    "        if(len(actions_hist)==2):\n",
    "            new_value = (1 - self.learning_rate) * self.qtable[actions_hist[1][0], actions_hist[1][1]] +  self.learning_rate * reward\n",
    "            self.qtable[actions_hist[1][0], actions_hist[1][1]] = new_value\n",
    "\n",
    "            back = (1 - self.learning_rate) * self.qtable[actions_hist[0][0], actions_hist[0][1]] +  self.learning_rate * (0 + (self.gamma/2) * reward)\n",
    "            self.qtable[actions_hist[0][0], actions_hist[0][1]] = back\n",
    "\n",
    "        if(len(actions_hist)==3):\n",
    "            new_value = (1 - self.learning_rate) * self.qtable[actions_hist[2][0], actions_hist[2][1]] +  self.learning_rate * reward\n",
    "            self.qtable[actions_hist[2][0], actions_hist[2][1]] = new_value\n",
    "\n",
    "            back = (1 - self.learning_rate) * self.qtable[actions_hist[1][0], actions_hist[1][1]] +  self.learning_rate * (0 + (self.gamma/2) * reward)\n",
    "            self.qtable[actions_hist[1][0], actions_hist[1][1]] = back\n",
    "\n",
    "            back_prime = (1 - self.learning_rate) * self.qtable[actions_hist[0][0], actions_hist[0][1]] +  self.learning_rate * (0 + (self.gamma/4) * reward)\n",
    "            self.qtable[actions_hist[0][0], actions_hist[0][1]] = back_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_number=100000\n",
    "evaluate_every=30\n",
    "test_number=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qAgent vs RandAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.201  0.355 -0.185]\n",
      " [-0.669  0.5    0.559]\n",
      " [-1.027  0.653  3.332]\n",
      " [-1.    -0.058 -1.063]\n",
      " [-1.     0.728 -0.853]\n",
      " [-1.     0.716  2.425]\n",
      " [-0.609  0.    -2.078]\n",
      " [-1.     0.    -2.241]\n",
      " [-0.739  0.     6.537]\n",
      " [-1.     1.121  5.85 ]\n",
      " [-1.    -0.419 -1.605]\n",
      " [-1.    -0.412 -3.231]\n",
      " [-1.    -0.389 -1.232]\n",
      " [-1.     0.958  5.288]\n",
      " [-1.     0.665  1.416]\n",
      " [-1.     0.342  1.459]\n",
      " [-1.     0.791  2.51 ]\n",
      " [-1.     1.304  4.322]\n",
      " [-0.654  0.996  5.753]\n",
      " [-0.266 -0.868 -3.031]\n",
      " [-0.655 -0.621 -1.176]\n",
      " [-0.453 -0.835 -3.081]\n",
      " [-0.162  1.229  5.52 ]\n",
      " [-0.629  0.446  0.126]\n",
      " [-0.081  0.295  0.777]\n",
      " [-0.492  0.029  3.261]\n",
      " [-0.501  1.439  4.738]\n",
      " [-0.92   0.     9.997]\n",
      " [-0.976  0.    -8.955]\n",
      " [-0.784  0.    -7.139]\n",
      " [-0.738  0.    -5.138]\n",
      " [-0.754  0.     9.989]\n",
      " [-0.999  0.     4.47 ]\n",
      " [-0.944  0.     2.094]\n",
      " [-0.937  0.     2.236]\n",
      " [-0.861  0.     9.98 ]]\n"
     ]
    }
   ],
   "source": [
    "randAgent=RandAgent()\n",
    "env=Environment(randAgent)\n",
    "qagent=QAgent()\n",
    "\n",
    "for i in range(epochs_number):\n",
    "    allowed_actions=[0,1,2]\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    while(env.game.is_game_over()==0):\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        \n",
    "        if (current_player==1):\n",
    "            env.agent.set_action(allowed_actions,0,0,0,0)\n",
    "            env.set_opponent_action(env.agent.get_action())\n",
    "            reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action())\n",
    "        if(env.game.is_game_over()==0):\n",
    "            qagent_action=qagent.explore_action(allowed_actions)\n",
    "            reward,allowed_actions, new_state=env.step(qagent_action)\n",
    "            if(env.game.is_game_over()==1):\n",
    "                qagent.update(reward, env.get_actions_hist())\n",
    "            qagent.set_state(new_state)\n",
    "        else:\n",
    "            env.reset()\n",
    "            allowed_actions=[0,1,2]\n",
    "            first_time=True\n",
    "    \n",
    "    env.reset()\n",
    "    \n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(qagent.qtable)\n",
    "random_agent_qtable=qagent.qtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qAgent vs GreedyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -0.718   0.127  -1.478]\n",
      " [ -0.994  -0.354  -0.441]\n",
      " [ -1.127  -0.479   1.276]\n",
      " [ -1.     -0.539  -0.35 ]\n",
      " [ -1.     -0.045   1.485]\n",
      " [ -1.      0.214   1.254]\n",
      " [ -1.      0.     -4.838]\n",
      " [ -0.904   0.     -1.658]\n",
      " [ -1.      0.      1.463]\n",
      " [ -1.      0.947   1.616]\n",
      " [ -1.     -1.173  -3.88 ]\n",
      " [ -1.     -0.931  -2.593]\n",
      " [ -1.     -0.56   -2.674]\n",
      " [ -1.      1.198   2.018]\n",
      " [ -1.     -0.003  -2.017]\n",
      " [ -1.     -0.65   -3.108]\n",
      " [ -1.     -0.875  -3.443]\n",
      " [ -1.      1.      1.   ]\n",
      " [ -0.997   0.979   1.143]\n",
      " [ -0.981  -0.904  -0.374]\n",
      " [ -0.797  -0.638   0.693]\n",
      " [ -0.998  -0.5    -2.744]\n",
      " [ -0.765   0.998   1.487]\n",
      " [ -0.744   0.444   0.915]\n",
      " [ -0.904   0.335  -0.255]\n",
      " [ -0.77    0.377   0.189]\n",
      " [ -0.978   0.88    0.947]\n",
      " [ -0.987   0.      9.995]\n",
      " [ -0.98    0.    -10.   ]\n",
      " [ -1.      0.    -10.   ]\n",
      " [ -1.      0.     -9.236]\n",
      " [ -0.613   0.      9.282]\n",
      " [ -1.      0.     -8.678]\n",
      " [ -1.      0.     -3.514]\n",
      " [ -1.      0.     -9.489]\n",
      " [ -0.999   0.      9.903]]\n"
     ]
    }
   ],
   "source": [
    "greedyAgent=GreedyAgent()\n",
    "env=Environment(greedyAgent)\n",
    "qagent=QAgent()\n",
    "\n",
    "for i in range(epochs_number):\n",
    "    allowed_actions=[0,1,2]\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    while(env.game.is_game_over()==0):\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        \n",
    "        if (current_player==1):\n",
    "            env.agent.set_action(allowed_actions,None, env.game.get_game_round(), env.game.get_hand_player2(),env.game.get_boardcard())\n",
    "\n",
    "            env.set_opponent_action(env.agent.get_action())\n",
    "            reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action())\n",
    "            \n",
    "        if(env.game.is_game_over()==0):\n",
    "            qagent_action=qagent.explore_action(allowed_actions)\n",
    "            reward,allowed_actions, new_state=env.step(qagent_action)\n",
    "            if(env.game.is_game_over()==1):\n",
    "                qagent.update(reward, env.get_actions_hist())\n",
    "            qagent.set_state(new_state)\n",
    "        else:\n",
    "            env.reset()\n",
    "            allowed_actions=[0,1,2]\n",
    "            first_time=True\n",
    "    \n",
    "    env.reset()\n",
    "    \n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(qagent.qtable)\n",
    "greedy_agent_qtable=qagent.qtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qAgent (trained with a random agent) vs HumanAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to play?\n",
      "\n",
      "For the actions:\n",
      "\t- 0 : Fold\n",
      "\t- 1 : Check\n",
      "\t- 2 : Push\n",
      "\n",
      "For the cards:\n",
      "\t- 0 : Jack\n",
      "\t- 1 : Queen\n",
      "\t- 2 : King\n",
      "\n",
      " \n",
      "allowed_actions=  [0, 1, 2]\n",
      "Your card = 0 \n",
      "Action of the QAgent =  2 \n",
      "\n",
      "\n",
      "Please enter an action :(0,1 or 2)\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "His action was:  2 \n",
      "He has a:  1 \n",
      "Sorry, you loose !!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "humanAgent=HumanAgent()\n",
    "env=Environment(humanAgent)\n",
    "qagent=QAgent()\n",
    "qagent.set_qtable(random_agent_qtable)\n",
    "\n",
    "print(\"How to play?\\n\\nFor the actions:\\n\\t- 0 : Fold\\n\\t- 1 : Check\\n\\t- 2 : Push\\n\\nFor the cards:\\n\\t- 0 : Jack\\n\\t- 1 : Queen\\n\\t- 2 : King\\n\\n \")\n",
    "for i in range(1):\n",
    "    allowed_actions=[0,1,2]\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    while(env.game.is_game_over()==0):\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        \n",
    "        if (current_player==1):\n",
    "            env.agent.set_action(allowed_actions,None, env.game.get_game_round(), env.game.get_hand_player2(),env.game.get_boardcard())\n",
    "            env.set_opponent_action(env.agent.get_action())\n",
    "            reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action())\n",
    "            if(env.game.is_game_over()==1):\n",
    "                print(\"You loose!! He has a:\", env.game.get_hand_player1(), \"\\n\\n\")\n",
    "        if(env.game.is_game_over()==0):\n",
    "            qagent_action=qagent.exploit_action(allowed_actions)\n",
    "            reward,allowed_actions, new_state=env.step(qagent_action)\n",
    "            if(env.game.is_game_over()==1):\n",
    "                if(reward<0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nCongratulation, you win !!!\\n\\n\" )\n",
    "                elif(reward>0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nSorry, you loose !!!\\n\\n\" )\n",
    "                elif(reward==0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nIt's a draw !!!\\n\\n\" )\n",
    "                qagent.update(reward, env.get_actions_hist())\n",
    "            qagent.set_state(new_state)\n",
    "\n",
    "    \n",
    "    env.reset()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qAgent (trained with a greedy agent) vs HumanAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to play?\n",
      "\n",
      "For the actions:\n",
      "\t- 0 : Fold\n",
      "\t- 1 : Check\n",
      "\t- 2 : Push\n",
      "\n",
      "For the cards:\n",
      "\t- 0 : Jack\n",
      "\t- 1 : Queen\n",
      "\t- 2 : King\n",
      "\n",
      " \n",
      "allowed_actions=  [0, 1, 2]\n",
      "Your card = 2 \n",
      "Action of the QAgent =  1 \n",
      "\n",
      "\n",
      "Please enter an action :(0,1 or 2)\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "allowed_actions=  [0, 2]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'remove'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2361883fd5a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You loose!! He has a:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_hand_player1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\n\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_game_over\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mqagent_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqagent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexploit_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallowed_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallowed_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqagent_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_game_over\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-6f69d0a02ebb>\u001b[0m in \u001b[0;36mexploit_action\u001b[1;34m(self, allowed_actions)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexploit_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"allowed_actions= \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_max_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\poker project\\utils.py\u001b[0m in \u001b[0;36mget_max_list\u001b[1;34m(l, allowed_actions)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallowed_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'remove'"
     ]
    }
   ],
   "source": [
    "humanAgent=HumanAgent()\n",
    "env=Environment(humanAgent)\n",
    "qagent=QAgent()\n",
    "qagent.set_qtable(greedy_agent_qtable)\n",
    "\n",
    "print(\"How to play?\\n\\nFor the actions:\\n\\t- 0 : Fold\\n\\t- 1 : Check\\n\\t- 2 : Push\\n\\nFor the cards:\\n\\t- 0 : Jack\\n\\t- 1 : Queen\\n\\t- 2 : King\\n\\n \")\n",
    "for i in range(1):\n",
    "    allowed_actions=[0,1,2]\n",
    "    current_player=env.game.get_firstplayer()\n",
    "    while(env.game.is_game_over()==0):\n",
    "        state=env.get_state()\n",
    "        qagent.set_state(state)\n",
    "        \n",
    "        if (current_player==1):\n",
    "            env.agent.set_action(allowed_actions,None, env.game.get_game_round(), env.game.get_hand_player2(),env.game.get_boardcard())\n",
    "            env.set_opponent_action(env.agent.get_action())\n",
    "            reward,current_player,allowed_actions=env.game.step_prime(env.agent.get_action())\n",
    "            if(env.game.is_game_over()==1):\n",
    "                print(\"You loose!! He has a:\", env.game.get_hand_player1(), \"\\n\\n\")\n",
    "        if(env.game.is_game_over()==0):\n",
    "            qagent_action=qagent.exploit_action(allowed_actions)\n",
    "            reward,allowed_actions, new_state=env.step(qagent_action)\n",
    "            if(env.game.is_game_over()==1):\n",
    "                if(reward<0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nCongratulation, you win !!!\\n\\n\" )\n",
    "                elif(reward>0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nSorry, you loose !!!\\n\\n\" )\n",
    "                elif(reward==0):\n",
    "                    print(\"His action was: \", qagent_action, \"\\nHe has a: \",env.game.get_hand_player1(), \"\\nIt's a draw !!!\\n\\n\" )\n",
    "                qagent.update(reward, env.get_actions_hist())\n",
    "            qagent.set_state(new_state)\n",
    "\n",
    "    \n",
    "    env.reset()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
